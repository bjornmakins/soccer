{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install dtreeviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data manipulation\\n\",\npd.options.mode.chained_assignment = None  # default='warn'\\n\",\nimport numpy as np #  mathematical support for large, multi-dimensional arrays and matrices\\n\",\nimport os\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeRegressor\nimport re\nimport sqlite3\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport collections\nfrom matplotlib.patches import Arc\nimport math\nimport xgboost\nimport dtreeviz\nfrom sklearn.model_selection import KFold\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## Import up sound alert dependencies\nfrom IPython.display import Audio, display\n\ndef allDone():\n  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n## Insert whatever audio file you want above\n\n# allDone()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Set Directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/kaggle/input/football-event-data')\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/group/interns202010/jmakins/Data')\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/Users/jordanmakins/Desktop/Data/Players')\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## When USING KAGGLE\n\nos.chdir('/kaggle/input/football-event-data')\n\n#Teams = pd.read_json('teams.json')\n#Competitions = pd.read_json('competitions.json')\nPlayers = pd.read_json('players.json')\n#Coaches = pd.read_json('coaches.json') # Managers\n\nEngland = pd.read_json('matches_England.json')\nFrance = pd.read_json('matches_France.json')\nItaly = pd.read_json('matches_Italy.json')\nSpain = pd.read_json('matches_Spain.json')\nGermany = pd.read_json('matches_Germany.json')\n\nEngland['Country'] = 'England'\nFrance['Country'] = 'France'\nItaly['Country'] = 'Italy'\nSpain['Country'] = 'Spain'\nGermany['Country'] = \"Germany\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/Users/jordanmakins/Desktop/Data')\nexcept:\n    pass\n\n\nTeams = pd.read_json('teams.json')\n#Competitions = pd.read_json('competitions.json')\nPlayers = pd.read_json('players.json')\n#Coaches = pd.read_json('coaches.json') # Managers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/Users/jordanmakins/Desktop/Data/matches')\nexcept:\n    pass\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/group/interns202010/jmakins/Data/matches')\nexcept:\n    pass\n\ntry:\n    os.chdir('/Users/jordanmakins/Desktop/Data/matches')\nexcept:\n    pass\n\nEngland = pd.read_json('matches_England.json')\nFrance = pd.read_json('matches_France.json')\nItaly = pd.read_json('matches_Italy.json')\nSpain = pd.read_json('matches_Spain.json')\nGermany = pd.read_json('matches_Germany.json')\n#World_Cup = pd.read_json('matches_World_Cup.json')\n#Euro_Champs = pd.read_json('matches_European_Championship.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding country labels to match observations\nEngland['Country'] = 'England'\nFrance['Country'] = 'France'\nItaly['Country'] = 'Italy'\nSpain['Country'] = 'Spain'\nGermany['Country'] = \"Germany\"\n#World_Cup['Country'] = 'World Cup'\n#Euro_Champs['Country'] = 'European Champs'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir('/group/interns202010/jmakins/Data/events')\nexcept:\n    pass\ntry:\n    os.chdir('/Users/jordanmakins/Desktop/Data/events')\nexcept:\n    pass\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Events_France = pd.read_json('events_France.json')\nEvents_Spain = pd.read_json('events_Spain.json')\nEvents_Germany = pd.read_json('events_Germany.json')\n#Events_EuroChamps = pd.read_json('events_European_Championship.json')\n#Events_World_Cup = pd.read_json('events_World_Cup.json')\nEvents_Italy = pd.read_json('events_Italy.json')\nEvents_England = pd.read_json('events_England.json')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches = pd.concat([England, France, Italy, Spain, Germany], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches.drop(['duration'], inplace=True, axis =1) # removing groupName variable from World Cups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Players.drop([\"passportArea\"], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Players = Players.rename(columns ={'wyId': 'playerId'}) # rename for convenience","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Teams = Teams.rename(columns = {'wyId': 'teamId'})\nPlayers = Players.rename(columns = {'currentTeamId': 'teamId'})\nPlayers = pd.merge(Players,Teams[['teamId', 'officialName']], on = 'teamId').rename(columns = {'officialName': 'clubName'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Players['Position'] = Players.role.apply(pd.Series)['code3'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Players['birthCountry'] = Players.birthArea.apply(pd.Series)['name'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Players.drop([\"birthArea\", 'role'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Manipulate Match Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"teams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"teams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match\nhomeTeam, awayTeam = [],[]\nfor x in teams:\n    homeTeam.append(x[0])\n    awayTeam.append(x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add columns for additional match statistics\nMatches[\"homeManagerId\"] = None\nfor name in [\"Score\", \"ScoreHT\", \"ScoreET\", \"ScoreP\"]:\n    colname = \"home\" + name\n    colname2 = \"away\" + name\n    Matches[colname] = None\n    Matches[colname2] = None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parse Home and Away teams as features from nest dictionary\nteams = [list(x.keys()) for x in Matches.teamsData] # create two columns for identifying teams in match\nhomeTeam, awayTeam = [],[]\nfor game, team in enumerate(teams):\n    if Matches.teamsData[game:game+1][game][team[0]]['side'] == 'home':\n        homeTeam.append(team[0])\n        awayTeam.append(team[1])\n    else:\n        awayTeam.append(team[0])\n        homeTeam.append(team[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_team_stats(df, team): # function to parse team match stats from dictionary embedded in column teamsData from the Matches dataframe\n    \n    Bench, Starters, Manager, Score, ScoreHT, ScoreET, ScoreP, teamId = [],[],[],[],[],[],[],[]\n    \n    for game in range(0, len(df)):\n\n        Bench.append(list(pd.DataFrame.from_dict(df.teamsData[game][team[game]]['formation']['bench'])['playerId']))\n        Starters.append(list(pd.DataFrame.from_dict(df.teamsData[game][team[game]]['formation']['lineup'])['playerId']))\n        Manager.append(df.teamsData[game][team[game]]['coachId'])\n        Score.append(df.teamsData[game][team[game]]['score'])\n        ScoreHT.append(df.teamsData[game][team[game]]['scoreHT'])\n        ScoreET.append(df.teamsData[game][team[game]]['scoreET'])\n        ScoreP.append(df.teamsData[game][team[game]]['scoreP'])\n        teamId.append(df.teamsData[game][team[game]]['teamId'])\n    \n    return Bench, Starters, Manager, Score, ScoreHT, ScoreET, ScoreP, teamId\n\nhomeBench, homeStarters, homeManager, homeScore, homeScoreHT, homeScoreET, homeScoreP, homeTeamId = get_team_stats(Matches, homeTeam)\nawayBench, awayStarters, awayManager, awayScore, awayScoreHT, awayScoreET, awayScoreP, awayTeamId = get_team_stats(Matches, awayTeam)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Automating Bench Line Up Column Generation\n\nhomeColNames = []\nfor num in range(1,14): # add columns for home bench playerId\n     homeColNames.append(\"homeBenchPlayer\" + str(num))\n        \nawayColNames = []\nfor num in range(1,14): # add columns for away bench playerId\n    awayColNames.append(\"awayBenchPlayer\" + str(num))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspecting bench counts as during errror handling reveals some matches had bench sizes of between 8 and 13 for certain fixtures\nimport collections\ncollections.Counter(list(map(lambda x: len(x), homeBench)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Bench Line Ups to DataFrame\n\nhomeBench2 = pd.DataFrame(homeBench,\n     columns=homeColNames)\nawayBench2 = pd.DataFrame(awayBench,\n     columns=awayColNames)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Automating Starting Line Up Column Generation\n\nhomeColNames =[]\nfor num in range(1,12): # add columns for starting playerId\n     homeColNames.append(\"homePlayer\" + str(num))\n        \nawayColNames = []\nfor num in range(1,12): # add columns for starting playerId\n    awayColNames.append(\"awayPlayer\" + str(num))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Joining starting line ups, benches to matches dataframe\n\nhomeStarters2 = pd.DataFrame(homeStarters,\n     columns=homeColNames)\nawayStarters2 = pd.DataFrame(awayStarters,\n     columns=awayColNames)\n\nMatches = Matches.join([homeStarters2, awayStarters2, homeBench2, awayBench2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add individual columns of match data\nMatches['homeManager'] = homeManager\nMatches['homeScore'] = homeScore\nMatches['homeScoreHT'] = homeScoreHT\nMatches['homeScoreET'] = homeScoreET\nMatches['homeScoreP'] = homeScoreP\nMatches['homeTeamId'] = homeTeamId\nMatches['awayManager'] = awayManager\nMatches['awayScore'] = awayScore\nMatches['awayScoreHT'] = awayScoreHT\nMatches['awayScoreET'] = awayScoreET\nMatches['awayScoreP'] = awayScoreP\nMatches['awayTeamId'] = awayTeamId","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches.drop([\"teamsData\"], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classify Match Result as W, L or D for teams\nconditions = [\n    (Matches['winner'] == 0),\n    (Matches['winner'] == Matches['awayTeamId']),\n    (Matches['winner'] == Matches['homeTeamId'])\n    ]\n\n# create a list of the values we want to assign for each condition\nvalues = [0, -1, 1]\n\n# create a new column and use np.select to assign values to it using our lists as arguments\nMatches['Result'] = np.select(conditions, values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches[\"date\"] = pd.to_datetime(Matches['dateutc']).dt.date # create a date column for Matches dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches[\"time\"] = pd.to_datetime(Matches['dateutc']).dt.time # create a time column for Matches dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prelim Dimensionality Reduction\ncols2Drop = ['status', 'roundId', 'gameweek', 'dateutc', 'label', 'referees', 'homeManagerId', 'seasonId']\nMatches.drop(cols2Drop, inplace=True, axis =1)\nMatches.drop(['winner', 'date', 'time'], inplace = True, axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches.rename(columns={'wyId':'matchId'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Matches = Matches.fillna(0) # fill bench7players with Ids = 0 in order to prevent program crashing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Events Manipulation for Match/Player Stats and then combine with existing Match(test) dataframe from aboves"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decroos Github\ntags = [\n    (101, \"goal\"),\n    (102, \"own_goal\"),\n    (301, \"assist\"),\n    (302, \"key_pass\"),\n    (1901, \"counter_attack\"),\n    (401, \"left_foot\"),\n    (402, \"right_foot\"),\n    (403, \"head/body\"),\n    (1101, \"direct\"),\n    (1102, \"indirect\"),\n    (2001, \"dangerous_ball_lost\"),\n    (2101, \"blocked\"),\n    (801, \"high\"),\n    (802, \"low\"),\n    (1401, \"interception\"),\n    (1501, \"clearance\"),\n    (201, \"opportunity\"),\n    (1301, \"feint\"),\n    (1302, \"missed_ball\"),\n    (501, \"free_space_right\"),\n    (502, \"free_space_left\"),\n    (503, \"take_on_left\"),\n    (504, \"take_on_right\"),\n    (1601, \"sliding_tackle\"),\n    (601, \"anticipated\"),\n    (602, \"anticipation\"),\n    (1701, \"red_card\"),\n    (1702, \"yellow_card\"),\n    (1703, \"second_yellow_card\"),\n    (1201, \"position_goal_low_center\"),\n    (1202, \"position_goal_low_right\"),\n    (1203, \"position_goal_mid_center\"),\n    (1204, \"position_goal_mid_left\"),\n    (1205, \"position_goal_low_left\"),\n    (1206, \"position_goal_mid_right\"),\n    (1207, \"position_goal_high_center\"),\n    (1208, \"position_goal_high_left\"),\n    (1209, \"position_goal_high_right\"),\n    (1210, \"position_out_low_right\"),\n    (1211, \"position_out_mid_left\"),\n    (1212, \"position_out_low_left\"),\n    (1213, \"position_out_mid_right\"),\n    (1214, \"position_out_high_center\"),\n    (1215, \"position_out_high_left\"),\n    (1216, \"position_out_high_right\"),\n    (1217, \"position_post_low_right\"),\n    (1218, \"position_post_mid_left\"),\n    (1219, \"position_post_low_left\"),\n    (1220, \"position_post_mid_right\"),\n    (1221, \"position_post_high_center\"),\n    (1222, \"position_post_high_left\"),\n    (1223, \"position_post_high_right\"),\n    (901, \"through\"),\n    (1001, \"fairplay\"),\n    (701, \"lost\"),\n    (702, \"neutral\"),\n    (703, \"won\"),\n    (1801, \"accurate\"),\n    (1802, \"not_accurate\"),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags = dict(tags)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## I have kept this cell encase we need to impute integers for ML algorithms as oppose to strings\n# event_tag_ids = []\n# for ids in  list(trial[0:10]['tags']):\n#     event_tag_ids.append(list(map(lambda y: y['id'], ids)))\n# trial['event_tag_ids'] = event_tag_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store event type tags ids in new column\ndef event_tags(event_df):\n    event_tags = []\n    for ids in list(event_df['tags']):\n        event_tags.append(list(map(lambda y: tags[y['id']], ids)))\n\n    event_df['event_tags'] = event_tags\n    return event_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RunningTime(event_df):\n    # Solution to convert second half time into \n    secs_to_add = list(event_df[event_df['matchPeriod']==\"1H\"].groupby('matchId').tail(1)['eventSec'])\n    match_ids = list(event_df[\"matchId\"].unique())\n\n    for idx in range(0, len(match_ids)):\n        event_df['eventSec'] = list(np.where(\n           (event_df['matchId'] == match_ids[idx]) & (event_df['matchPeriod'] == \"2H\") , event_df['eventSec'] + secs_to_add[idx], event_df['eventSec']\n           ))\n    return event_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the result of the action\ndef Result(event_df):\n    result = []\n    for tag in event_df[\"event_tags\"]:\n        if \"accurate\" in tag:\n            result.append(\"Accurate\")\n        elif \"not_accurate\" in tag:\n            result.append(\"Inaccurate\")\n        else:\n            result.append(\"\")\n    event_df[\"Result\"] = result \n    return event_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating description from success/failure of an action (event)\ndef event_description(event_df):\n    subEventDescr = []\n    for tag in event_df[\"event_tags\"]:\n        descr = \" \".join(tag[:-1])\n        if descr != \"\":\n            subEventDescr.append(descr)\n        else:\n            subEventDescr.append(\"generic play\")\n    event_df[\"subEventDescription\"] = subEventDescr\n    event_df = event_df[(event_df[\"event_tags\"].str.len() != 0) & (event_df.subEventName != 'Ball out of the field')  & (event_df.subEventName != 'Goal kick')  ]\n    event_df = event_df[event_df[\"subEventName\"] != \"Throw in\"] # remove throw-ins as a relevant feature among successful teams for simpler analysis, unless its Rory Delap!\n    return event_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Separating description from success/failure of an action (event)\n# def event_description(event_df):\n#     subEventDescr = []\n#     for tag in event_df[\"event_tags\"]:\n#         descr = \" \".join(tag[:-1])\n#         if descr != \"\":\n#             subEventDescr.append(descr)\n#         else:\n#             subEventDescr.append(\"generic play\")\n#     event_df[\"subEventDescription\"] = subEventDescr\n#     event_df = event_df[(event_df[\"event_tags\"].str.len() != 0) & (event_df.subEventName != 'Ball out of the field')  & (event_df.subEventName != 'Goal kick') & (event_df.subEventName != 'Touch')   ]\n#     event_df = event_df[event_df[\"subEventName\"] != \"Throw in\"] # remove throw-ins as a relevant feature among successful teams for simpler analysis, unless its Rory Delap!\n#     return event_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef Locations(event_df):\n\n    xStart,xEnd,yStart,yEnd = [], [], [], []\n    for pos in event_df[\"positions\"]:\n        if len(pos) == 2:\n            xStart.append(pos[0]['x'])\n            xEnd.append(pos[1]['x'])\n            yStart.append(pos[0]['y'])\n            yEnd.append(pos[1]['y'])\n        else:\n            xStart.append(pos[0]['x'])\n            xEnd.append(pos[0]['x'])\n            yStart.append(pos[0]['y'])\n            yEnd.append(pos[0]['y'])\n\n\n    event_df['xStart'], event_df['xEnd'], event_df['yStart'], event_df['yEnd'] = xStart, xEnd, yStart, yEnd\n    return event_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to transform an event data frame\ndef event_df_transform(event_df):\n    event_df = event_tags(event_df)\n    event_df = Result(event_df)\n    event_df = event_description(event_df)\n    event_df = Locations(event_df)\n    event_df.drop(['positions', \"event_tags\", \"tags\", \"eventName\"], inplace = True, axis = 1) #'id'\n    event_df = event_df[event_df.subEventName != \"\"]\n    event_df = event_df[event_df['playerId']!= 0]\n    event_df = RunningTime(event_df)\n    event_df['attackMetres'] = event_df['xEnd'] - event_df['xStart']\n    return event_df\n\n# stopped remove eventId\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform event_dfs\n\nEvents_France = event_df_transform(Events_France)\nEvents_Spain = event_df_transform(Events_Spain)\nEvents_Germany = event_df_transform(Events_Germany)\nEvents_Italy = event_df_transform(Events_Italy)\nEvents_England = event_df_transform(Events_England)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def zones(event_df, start_or_end):\n\n    conditions = [\n            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <= 36))),\n            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 36)& (event_df['y'+ start_or_end] <= 64))),\n            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 64)& (event_df['y'+ start_or_end] <= 75))),\n            (((event_df['x'+ start_or_end] < 16.5)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n        \n            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <=  25))),\n            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <=  75))),\n            (((event_df['x'+ start_or_end] <= 33)& (event_df['x'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <=  100))),\n            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] >= 0))& (event_df['y'+ start_or_end] <=  25)),\n            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <=  75))),\n            (((event_df['x'+ start_or_end] <= 50)& (event_df['x'+ start_or_end] > 33) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <=  100))),\n            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <=  50))),\n            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <= 75))),\n            (((event_df['x'+ start_or_end] <= 67)& (event_df['x'+ start_or_end] > 50) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] >= 0)& (event_df['y'+ start_or_end] <= 25))),\n            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 25)& (event_df['y'+ start_or_end] <= 50))),\n            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 50)& (event_df['y'+ start_or_end] <= 75))),\n            (((event_df['x'+ start_or_end] < 83.5)& (event_df['x'+ start_or_end] > 67) & (event_df['y'+ start_or_end] > 75)& (event_df['y'+ start_or_end] <= 100))),\n        \n            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] >= 0) & (event_df['y'+ start_or_end] <= 25))),\n            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 25) & (event_df['y'+ start_or_end] <=  36))),\n            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 36) & (event_df['y'+ start_or_end] <= 64))),\n            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 64) & (event_df['y'+ start_or_end] <= 75))),\n            (((event_df['x'+ start_or_end] <= 100) & (event_df['x'+ start_or_end] > 83.5) & (event_df['y'+ start_or_end] > 75) & (event_df['y'+ start_or_end] <= 100)))\n            ]\n\n    # create a list of the values we want to assign for each condition\n    values = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n\n    # create a new column and us np.select to assign values to it using our lists as arguments\n    event_df['Zone'+ start_or_end] = np.select(conditions, values)\n    \n    return event_df\n\n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for event_df in [Events_England, Events_Italy, Events_Spain, Events_France, Events_Germany]:\n    event_df = zones(event_df, \"Start\")\n    event_df = zones(event_df, \"End\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### CHange German row with 101\nEvents_Germany.loc[Events_Germany.yEnd==101, ['yEnd']] = 99","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### remove events where playerId equals zero\n## There are two instances where goals are scored so we will handle these first and assign to correct players as these are important events\n# we can attempt to handle these into the real player sequences if we have time at the end of the project\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to determine average player coordinates on pitch across all possessions in a match\ndef playerPosition(event_df):\n    df = event_df.groupby(['matchId','playerId']).agg({'xStart': ['mean'], 'yStart': ['mean']}).reset_index()\n    df.columns = [\"matchId\", \"playerId\", \"xStart\", \"yStart\"]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# find positions for all players for big 5 Euro leagues\na = playerPosition(Events_England)\nb = playerPosition(Events_France)\nc = playerPosition(Events_Italy)\nd = playerPosition(Events_Spain)\ne = playerPosition(Events_Germany)\n\nposition_df = pd.concat([a,b,c,d,e])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# This dataframe is used relationally to fill correct team as events represent 2018 team, while player\na = Events_England[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\nb = Events_France[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\nc = Events_Italy[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\nd = Events_Spain[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\ne = Events_Germany[['playerId', \"teamId\", 'matchId']].groupby(['playerId', \"teamId\", 'matchId']).count().reset_index()\np_refs = pd.concat([a,b,c,d,e])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create PA dataframe\nPlayer_Aggs = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\n\n# add ave field locations to players\nPlayer_Aggs = pd.merge(Player_Aggs, position_df, how = 'right', on= 'playerId').sort_values('matchId')\nPlayer_Aggs = pd.merge(Player_Aggs, p_refs, on = ['matchId', 'playerId'])\nPlayer_Aggs = pd.merge(Player_Aggs, Teams[['teamId', 'name']], on = 'teamId')\nPlayer_Aggs = pd.merge(Player_Aggs, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\nPlayer_Aggs.loc[Player_Aggs.teamId == Player_Aggs.homeTeamId, 'homeAway'] = \"home\"\nPlayer_Aggs.loc[Player_Aggs.teamId == Player_Aggs.awayTeamId, 'homeAway'] = \"away\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # # # #\n\n# var = \"Shot\"\n# varName = \"ShotsOnTarget\"\n\n# # this exists\n# df = Events_England.loc[(Events_England.Result == \"Accurate\" ) & (Events_England.subEventName== var )].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOnTarget')#.groupby([\"matchId\",'playerId']).agg(list).reset_index()\n# # [['playerId', 'matchId', \"ZoneStart\"]]\n# # # # # # # \n\ndef transform_zonal(df, varName):\n\n    df = df.pivot_table(varName, ['playerId', 'matchId'], 'ZoneStart').fillna(0).reset_index()\n\n    column_indices = []\n    new_names = []\n    check_cols = list(range(1,27))\n    old_columns = list(df.columns[2:])\n\n    for num, col in enumerate(old_columns):\n        column_indices.append(num+2)\n        new_names.append(varName+ \"_ZoneS_\" + str(col))\n\n    # columns to be added \n    change_cols = np.setdiff1d(check_cols, old_columns) \n\n    old_names = df.columns[column_indices]\n    df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n\n    for col in change_cols:\n        df[varName + \"_ZoneS_\" + str(col)] = 0\n\n    return df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### unique entry dataframe for player gameTime at any point in a match by summarizing streams\n\ndef playerGameTime(event_df):\n    df = event_df.groupby(['matchId','playerId'])['eventSec'].agg(['max', 'min']).reset_index()\n    df['gameTime (min)'] = round((df['max'] - df['min'])/60) # game time to the nearest minute\n    df.drop(['max', 'min'], inplace=True, axis=1)\n    return df\n\n# derive gameTime per player and store in summary table\na = playerGameTime(Events_England)\nb = playerGameTime(Events_France)\nc = playerGameTime(Events_Italy)\nd = playerGameTime(Events_Spain)\ne = playerGameTime(Events_Germany)\n\nplayingTime = pd.concat([a,b,c,d,e]).fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_goals(event_df):\n\n    # Create a column to recognize when a goal is scored\n    conditions = [\n        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Accurate\"))),\n        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Inaccurate\") & (event_df['subEventName'] == \"Shot\"))),\n        (((event_df['subEventDescription'].str.match('goal ')) & (event_df['Result'] == \"Inaccurate\") & (event_df['subEventName'] != \"Shot\")))\n        ]\n\n    # create a list of the values we want to assign for each condition\n    values = [1, 1, -1]\n\n    # create a new column and use np.select to assign values to it using our lists as arguments\n    event_df['Goal_Value'] = np.select(conditions, values, default = 0)\n    #[['playerId', 'matchId', \"ZoneStart\"]].groupby(['playerId', 'matchId', \"ZoneStart\"])\n    return event_df.groupby(['playerId', 'matchId', \"ZoneStart\"]).sum().reset_index()#[['playerId', 'matchId', 'Goal_Value']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for event in [Events_England, Events_Italy, Events_France, Events_Germany, Events_Spain]:\n    event = find_goals(event)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs = pd.merge(Player_Aggs, playingTime, how = 'left', on = ['playerId', 'matchId'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convenience function for event_df parsing\ndef parseEvent_df(func, new_feature):\n    \n    aa = func(Events_England)\n    aa = transform_zonal(aa, new_feature)\n#     aa = aa.rename_axis(None, axis=1)\n    bb = func(Events_France)\n    bb = transform_zonal(bb, new_feature)\n#     bb = bb.rename_axis(None, axis=1)\n    cc = func(Events_Italy)\n    cc = transform_zonal(cc, new_feature)\n#     cc = cc.rename_axis(None, axis=1)\n    dd = func(Events_Spain)\n    dd = transform_zonal(dd, new_feature)\n#     dd = dd.rename_axis(None, axis=1)\n    ee = func(Events_Germany)\n    ee = transform_zonal(ee, new_feature)\n#     ee = ee.rename_axis(None, axis=1)\n    \n    return pd.concat([aa,bb,cc,dd,ee])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for adding new feature column to Player_Aggs df\ndef alter_Player_Aggs(new_feature_function, new_feature, PA_df):\n    \n    if \"Acc\" in new_feature:\n        df = parseEvent_df(new_feature_function, new_feature)\n        #df = transform_zonal(df, new_feature)\n        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n#         new_cols = [col for col in df if col.startswith(new_feature)]\n#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n        \n    elif 'acc' in new_feature:\n        df = parseEvent_df(new_feature_function, new_feature)\n        #df = transform_zonal(df, new_feature)\n        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n#         new_cols = [col for col in df if col.startswith(new_feature)]\n#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n        \n    else:\n        df = parseEvent_df(new_feature_function, new_feature)\n        #df = transform_zonal(df, new_feature)\n        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n#         new_cols = [col for col in df if col.startswith(new_feature)]\n#         PA_df[new_cols] = PA_df[new_cols].fillna(0)\n        \n#         PA_df[new_cols] = (PA_df[new_cols] / PA_df['gameTime (min)']) * 90 # get standardized stat index for 90mins\n    PA_df.iloc[:,15:] = PA_df.iloc[:,15:].fillna(0)\n    return PA_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import datetime\n# while datetime.datetime.now().hour < 17:\n#     x = 1+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calc angle to goal from any location in radians\n\ndef angleToGoal(event_df):\n    \n    event_df['C'] = 10 # length of goal\n    event_df['A'] = ((100-event_df.xStart)**2+abs(45-event_df.yStart)**2)**.5\n    event_df['B'] = ((100-event_df.xStart)**2+abs(55-event_df.yStart)**2)**.5\n    event_df['angle_to_goal'] = (event_df['A'] * event_df['A'] + event_df['B'] * event_df['B'] - event_df['C'] * event_df['C'])/(2 * event_df['A'] * event_df['B'])\n    event_df['angle_to_goal'] = event_df['angle_to_goal'].apply(lambda row: round(math.radians(math.degrees(math.acos(row))),4))\n    # event_df['angle_to_goal'] = event_df['angle_to_goal'].apply(lambda row: round(math.degrees(row),2))\n    event_df.drop(['A', \"B\", \"C\"], inplace = True, axis=1)\n    return event_df\n        \nEvents_England, Events_France = angleToGoal(Events_England), angleToGoal(Events_France)\nEvents_Germany, Events_Spain = angleToGoal(Events_Germany), angleToGoal(Events_Spain)\nEvents_Italy = angleToGoal(Events_Italy)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to prepare dataframe for fdnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"# result is event_df\n\ndef player_goals(result):\n    \n    conditions = [\n            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Accurate\"))),\n            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Inaccurate\") & (result['subEventName'] == \"Shot\"))),\n            (((result['subEventDescription'].str.match('goal ')) & (result['Result'] == \"Inaccurate\") & (result['subEventName'] != \"Shot\")))\n            ]\n\n    # create a list of the values we want to assign for each condition\n    values = [1, 1, -1]\n\n    # create a new column and us np.select to assign values to it using our lists as arguments\n    result['Goal_Value'] = np.select(conditions, values, default = 0)\n    \n    return result\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def corner_assists(event_df):\n    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerAssists')\n\ndef corner_opportunity(event_df):\n    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('key_pass'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerOpportunitiesCreated')\n\ndef corner_success(event_df):\n    return event_df[(event_df.subEventName==\"Corner\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulCorners')\n\ndef corner_fail(event_df):\n    return event_df[(event_df.subEventName==\"Corner\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FailedCorners')\n\ndef corner_assists(event_df):\n    return event_df[(event_df.subEventName==\"Corner\") & (event_df.subEventDescription.str.match('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CornerAssists')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Attack Metres stat (how many forward metres achieved through events)\ndef AccBackwardMetres(event_df):\n\n    df = event_df.loc[(event_df.Result == \"Accurate\" ) & (event_df.attackMetres < 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccBackMetres\"})\n    df[\"AccBackMetres\"] = df[\"AccBackMetres\"].abs()\n    return df\n\ndef InaccBackwardMetres(event_df):\n\n    df = event_df.loc[(event_df.Result == \"Inaccurate\") & (event_df.attackMetres < 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccBackMetres\"})\n    df[\"InaccBackMetres\"] = df[\"InaccBackMetres\"].abs()\n    return df\n\n\n### Attack Metres stat (how many forward metres achieved through events)\ndef AccForwardMetres(event_df):\n\n    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.attackMetres > 0 )].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccForwardMetres\"})\n    return df\n\ndef InaccForwardMetres(event_df):\n\n    df = event_df.loc[(event_df.Result == \"Inaccurate\") & (event_df.attackMetres > 0 ) ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccForwardMetres\"})\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# adding in total meterage of accurate and inaccurate movements by players in the vertical plane towards the goal\n# AccBackward = parseEvent_df(AccBackwardMetres)\n# InaccBackward = parseEvent_df(InaccBackwardMetres)\n# AccForward = parseEvent_df(AccForwardMetres)\n# InaccForward= parseEvent_df(InaccForwardMetres)\n\n# Player_Aggs = pd.merge(Player_Aggs, AccBackward, how= 'left', on =['playerId', 'matchId'])\n# Player_Aggs = pd.merge(Player_Aggs, InaccBackward, how = 'left', on =['playerId', 'matchId'])\n# Player_Aggs = pd.merge(Player_Aggs, AccForward, how= 'left', on =['playerId', 'matchId'])\n# Player_Aggs = pd.merge(Player_Aggs, InaccForward, how = 'left', on =['playerId', 'matchId'])\n# Player_Aggs.AccForwardMetres = Player_Aggs.AccForwardMetres.fillna(0)\n# Player_Aggs.InaccForwardMetres = Player_Aggs.InaccForwardMetres.fillna(0)-\n# Player_Aggs.AccBackMetres = Player_Aggs.AccBackMetres.fillna(0)\n# Player_Aggs.InaccBackMetres = Player_Aggs.InaccBackMetres.fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Explore Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"Events_England.subEventName.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Miscellanous "},{"metadata":{"trusted":true},"cell_type":"code","source":"def SimulationFouls(event_df):\n    df = event_df[(event_df.subEventName==\"Simulation\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SimulationFouls')\n    return df\n\ndef Fouls(event_df):\n    df= event_df[(event_df.subEventName.str.contains('foul'))| (event_df.subEventName.str.contains('Foul'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FoulsCommited')\n\n    return df\n\ndef Clearances(event_df):\n    df =  event_df[(event_df.subEventName==\"Clearance\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Clearances')\n\n    return df\n    \ndef AccLaunchMetres(event_df):\n    df =  event_df.loc[(event_df.Result == \"Accurate\") &(event_df.subEventName==\"Launch\")].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccLaunchMetres\"})\n\n    return df\n    \ndef InaccLaunchMetres(event_df):\n    df = event_df.loc[(event_df.Result == \"Inaccurate\") &(event_df.subEventName==\"Launch\")].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"InaccLaunchMetres\"})\n\n    return df\n\ndef FreeKickCrossKey(event_df):\n    df = event_df[(event_df.subEventName == \"Free kick cross\")&(event_df.subEventDescription.str.contains(\"key\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FKKeyCross')\n\n    return df\n        \ndef FreeKickCrossAssists(event_df):\n    df = event_df[(event_df.subEventName == \"Free kick cross\")&(event_df.subEventDescription.str.contains(\"assist\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FKCrossAssists')\n    return df\n    \ndef FreeKickCrossAccuracy(event_df):\n    df1= event_df[(event_df.subEventName == \"Free kick cross\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickCrosses')\n    df2 = event_df[(event_df.subEventName == \"Free kick cross\")& (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccFreeKickCrosses')\n\n    return df2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#penaltiesConversion Statistic\n\ndef PenaltiesConverted(event_df):\n    df1= event_df[(event_df.subEventName == \"Penalty\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltiesAttempted')\n\n    df2 = event_df[(event_df.subEventName == \"Penalty\")& (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltiesScored')\n\n    df1 = pd.merge(df1,df2, how='left', on = ['matchId', 'playerId'])\n    df1['PenaltiesScored'] = df1['PenaltiesScored'].fillna(0)\n    df1['penaltiesConversion'] = df1['PenaltiesScored'] / df1['PenaltiesAttempted']\n    df1.drop(['PenaltiesScored', 'PenaltiesAttempted' ], inplace=True, axis =1)\n\n\n    return df1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'Ground loose ball duel', 'Ground defending duel'\ndef dangerousOpponentHalfRecoveries(event_df):\n    df = event_df[((event_df.subEventDescription.str.contains(\"won\")) | (event_df.subEventDescription.str.contains(\"interception\") & (event_df.Result==\"Accurate\"))) & (event_df.subEventName!=\"Ground attacking duel\") & (event_df.xEnd > 60)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousOpponentHalfRecoveries')\n    return df\n    \ndef dangerousOwnHalfBallLost(event_df):\n    df = event_df[(event_df.Result==\"Inaccurate\") & (event_df.xEnd<40) & ((event_df.subEventName.str.contains(\"pass\")) | (event_df.subEventName.str.contains(\"Acceleration\")) | (event_df.subEventName.str.contains(\"Clearance\")) | ((event_df.subEventName.str.contains(\"duel\")) &(event_df.subEventName!='Ground defending duel')) | (event_df.subEventName.str.contains(\"Launch\")))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousOwnHalfBallLost')\n    return df\n    \n    \ndef dangerousDefDuelsLost(event_df):\n    df = event_df[(event_df.Result==\"Inaccurate\") & (event_df.xEnd<40) & (event_df.subEventName==\"Ground defending duel\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='dangerousDefDuelsLost')\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Step one proportion of low left shots saved\n\npossies = ['low_left', 'mid_left', 'high_left', 'low_center', 'mid_center', 'high_center', 'low_right', 'mid_right', 'high_right']\n\ndef GoalKeepingZoneEfficiency(event_df, pos):\n    df1= event_df[((event_df.subEventName==\"Save attempt\") | (event_df.subEventName==\"Reflexes\")) &(event_df.subEventDescription.str.contains(pos))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='total_'+pos)\n\n    df2 = event_df[((event_df.subEventName==\"Save attempt\") | (event_df.subEventName==\"Reflexes\")) &(event_df.subEventDescription.str.contains(pos)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name=pos+'_saves')\n\n    df1 = pd.merge(df1,df2, how='left', on = ['matchId', 'playerId'])\n    df1[pos+'_saves'] = df1[pos+'_saves'].fillna(0)\n    df1[pos+'_save_efficiency'] = df1[pos+'_saves'] / df1['total_'+pos]\n    df1.drop([pos+'_saves', 'total_'+pos], inplace=True, axis =1)\n#     df1 = transform_zonal(df1, desiredName)\n    return df1\n\n\n# for pos in possies:\n#     a = GoalKeepingZoneEfficiency(Events_England, pos)\n#     b = GoalKeepingZoneEfficiency(Events_France, pos)\n#     c = GoalKeepingZoneEfficiency(Events_Italy, pos)\n#     d = GoalKeepingZoneEfficiency(Events_Spain, pos)\n#     e = GoalKeepingZoneEfficiency(Events_Germany, pos)\n#     df = pd.concat([a,b,c,d,e])\n#     Player_Aggs = pd.merge(Player_Aggs, df, how= 'left', on = ['playerId', 'matchId'])\n#     Player_Aggs[ pos + '_save_efficiency'] = Player_Aggs[pos + '_save_efficiency'].fillna(0)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Goals allowed\ndef goalsAllowed(event_df):\n    df = event_df[((event_df.subEventName == \"Reflexes\")|(Events_England.subEventName == \"Save attempt\")) & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='goalsAllowed')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Successful save attempt\ndef Saves(event_df):\n    df= event_df[((event_df.subEventName == \"Save attempt\")|(Events_England.subEventName == \"Save attempt\"))&(event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GkSaves')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Hand Pass\ndef SuccessHandPass(event_df):\n    df= event_df[(event_df.subEventName == \"Hand pass\")&(event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateHandPass')\n#     df = transform_zonal(df, desiredName)\n    return df\n# Inaccurate Hand Pass\ndef FailedHandPass(event_df):\n    df = event_df[(event_df.subEventName == \"Hand pass\")&(event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateHandPass')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# GoalKeeper Leaving Line \ndef LeavingLine(event_df):\n    df = event_df[(event_df.subEventName==\"Goalkeeper leaving line\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GKLeavingLineInstance')\n#     df = transform_zonal(df, desiredName)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Crosses, Dribbles, Accelerations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of succesful accelerations\ndef SuccessAccelerations(event_df):\n    df = event_df[(event_df.subEventName == 'Acceleration') & (event_df.Result == 'Accurate')].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulAccels')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Number of failed accelerations\ndef FailedAccelerations(event_df):\n    df = event_df[(event_df.subEventName == 'Acceleration') & (event_df.Result == 'Inaccurate')].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FailedAccels')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Total acceleration metres\ndef AccelDistance(event_df):\n    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"CumAccelerationDist\"})\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accelerations into final third\ndef AccelsIntoFinalThird(event_df):\n    df= event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") & (event_df.xStart <= 66)  & (event_df.xEnd > 66)].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccelsDistIntoFinal3rd\"})\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Acceleration within final third\ndef AccelsWithinFinalThird(event_df):\n    df = event_df.loc[(event_df.Result == \"Accurate\") & (event_df.subEventName==\"Acceleration\") & (event_df.xStart > 66) ].groupby(['playerId', 'matchId', \"ZoneStart\"])['attackMetres'].sum().reset_index().rename(columns={'attackMetres': \"AccelsDistWithinFinal3rd\"})\n#     df = transform_zonal(df, desiredName)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Crossing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cross assists\ndef crossAssists(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('assist'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CrossAssists')\n    df = transform_zonal(df, desiredName)\n    return df\n\n# right foot crosses\ndef RightFootCross(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('right_foot'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='RightFootCross')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# left foot crosses\ndef LeftFootCross(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('left_foot'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='LeftFootCross')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# cross key passes\ndef CrossKeyPasses(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.subEventDescription.str.contains('key_pass'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CrossKeyPass')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# accurate crosses\ndef AccurateCrosses(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccCrosses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# inaccurate crosses\ndef InaccurateCrosses(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccCrosses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate crosses into penalty box\ndef AccCrossesBox(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') \n               & (event_df.Result==\"Accurate\") \n               & (event_df.xEnd > 82)\n               & (event_df.yEnd < 80)\n               & (event_df.yEnd > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccCrossesIntoBox')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate crosses into penalty box\ndef InaccCrossesBox(event_df):\n    df = event_df[(event_df.subEventName == 'Cross') \n               & (event_df.Result==\"Inaccurate\") \n               & (event_df.xEnd > 82)\n               & (event_df.yEnd < 80)\n               & (event_df.yEnd > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccCrossesIntoBox')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Tackles & Ground Duels"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sliding tackles won\ndef slidingTacklesWon(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains(\"sliding_tackle won\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SlidingTacklesWon')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Sliding tackles lost\ndef slidingTacklesLost(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains(\"sliding_tackle lost\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SlidingTacklesLost')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground Defending Duels Won\ndef GroundDuelsWon(event_df):\n    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"won\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundDefDuelsWon')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground Defending Duels Lost\ndef GroundDuelsLost(event_df):\n    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"lost\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundDefDuelsLost')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground Defensive Anticipations\ndef GroundDefAnticipations(event_df):\n    df = event_df[(event_df.subEventName==\"Ground defending duel\") & event_df.subEventDescription.str.contains(\"anticipated\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='DefensiveAnticipations')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground Loose Balls Won\ndef GroundLooseBallsWon(event_df):\n    df = event_df[(event_df.subEventName == 'Ground loose ball duel') &(event_df.subEventDescription.str.contains('won'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundLooseBallsWon')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground Loose Balls Lost\ndef GroundLooseBallsLost(event_df):\n    df = event_df[(event_df.subEventName == 'Ground loose ball duel') &(event_df.subEventDescription.str.contains('lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundLooseBallsLost')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground attacking duels won\ndef GroundAttackDuelsWon(event_df):\n    df = event_df[(event_df.subEventName == 'Ground attacking duel') &(event_df.subEventDescription.str.contains('won'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundAttackDuelsWon')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Ground attacking duels lost\ndef GroundAttackDuelsLost(event_df):\n    df = event_df[(event_df.subEventName == 'Ground attacking duel') &(event_df.subEventDescription.str.contains('lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='GroundAttackDuelsLost')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Offensive Touches in box\ndef OffTouchesBox(event_df):\n    df = event_df[(event_df.subEventName == 'Touch')\n              & (event_df.xStart > 82)\n              & (event_df.yStart < 80)\n              & (event_df.yStart > 20)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='OffensiveTouchesBox')\n#     df = transform_zonal(df, desiredName)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Shots & Goals"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shots on Target\ndef ShotsOnTarget(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOnTarget')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Shots off Target\ndef ShotsOffTarget(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotsOffTarget')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Shot opportunity\ndef shot_opportunities(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.contains(\"opportunity\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotOpportunities')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate free kick shots\ndef accFreeKicks(event_df):\n    df = event_df[(event_df.subEventName==\"Free kick shot\") & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickShotAcc')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate free kick shots\ndef InaccFreeKicks(event_df):\n    df = event_df[(event_df.subEventName==\"Free kick shot\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='FreeKickShotInacc')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Did not score penalty\ndef PenaltyNotGoal(event_df):\n    df = event_df[(event_df.subEventName==\"Penalty\") & (event_df.Result==\"Inaccurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PenaltyNotScored')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Goal scored with head/body\ndef HeaderGoal(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n              & (event_df.subEventDescription.str.contains(\"head\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Header/Body_Goal')\n#     df = transform_zonal(df, desiredName)\n    return df    \n    \n# Goal scored with right foot\ndef RightFootGoal(event_df): \n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n              & (event_df.subEventDescription.str.contains(\"right_foot\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='RightFootGoal')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Goal scored with left foot\ndef LeftFootGoal(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n              & (event_df.subEventDescription.str.contains(\"left_foot\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='LeftFootGoal')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Counter Attack Goal\ndef CounterAttackGoal(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n              & (event_df.subEventDescription.str.contains(\"counter_attack\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackGoal')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Interception Goal\ndef InterceptionGoal(event_df):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n                & (event_df.subEventDescription.str.contains(\"interception\"))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InterceptionGoal')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Goal positions\ndef GoalPositions(event_df, pos):\n    df = event_df[(event_df.subEventName==\"Shot\") & (event_df.subEventDescription.str.match(\"goal \"))\n                  & (event_df.subEventDescription.str.contains(pos))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='Goal_'+pos)\n#     df = transform_zonal(df, desiredName)\n    return df\n\ndef OwnGoals(event_df):\n    df = event_df[event_df.subEventDescription.str.contains(\"own\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='OwnGoals')\n#     df = transform_zonal(df, desiredName)\n    return df\n\ndef shotAccuracy(event_df):\n    df1 = event_df[(event_df.subEventName.str.contains('Shot')) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotAccuracy1')\n    df2 = event_df[(event_df.subEventName.str.contains('Shot')) ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='ShotAccuracy2')\n    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n    df1['shotAccuracy'] = df1['ShotAccuracy1'] / df1['ShotAccuracy2']\n    df1.drop(['ShotAccuracy1', 'ShotAccuracy2'], inplace=True, axis =1)\n#     df1 = transform_zonal(df, desiredName)\n    return df1\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Get positional zones of goals for players\n\n# possies = ['low_left', 'mid_left', 'high_left', 'low_center', 'mid_center', 'high_center', 'low_right', 'mid_right', 'high_right']\n# for pos in possies:\n#     a = GoalPositions(Events_England, pos)\n#     b = GoalPositions(Events_France, pos)\n#     c = GoalPositions(Events_Italy, pos)\n#     d = GoalPositions(Events_Spain, pos)\n#     e = GoalPositions(Events_Germany, pos)\n#     df = pd.concat([a,b,c,d,e])\n#     Player_Aggs = pd.merge(Player_Aggs, df, how= 'left', on =['playerId', 'matchId'])\n#     Player_Aggs[\"Goal_\"+pos] = Player_Aggs[\"Goal_\"+pos].fillna(0)\n\n# Player_Aggs = Player_Aggs.drop_duplicates()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"####   Air duel"},{"metadata":{"trusted":true},"cell_type":"code","source":"def AerialDuelsWon(events_df):\n    df = Events_England[(Events_England.subEventName==\"Air duel\") & (Events_England.subEventDescription.str.contains(\"won\"))].groupby(['playerId', 'matchId', 'ZoneStart']).size().reset_index(name='AerialDuelsWon')\n#     df = transform_zonal(df, desiredName)\n    return df\n\ndef AerialDuelsLost(events_df):\n    df =  Events_England[(Events_England.subEventName==\"Air duel\") & (Events_England.subEventDescription.str.contains(\"lost\"))].groupby(['playerId', 'matchId', 'ZoneStart']).size().reset_index(name='AerialDuelsLost')\n#     df = transform_zonal(df, desiredName)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Passing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accurate forward passes\ndef acc_forward_pass(event_df):\n    df = event_df[(event_df.subEventName==\"Simple pass\") \n                   & (event_df.attackMetres>0)\n                   & (event_df.Result==\"Accurate\")\n                   & (event_df.subEventDescription.str.match('generic play'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateForwardPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate forward passes \ndef inacc_forward_passes(event_df):\n    df = event_df[(event_df.subEventName==\"Simple pass\") \n                   & (event_df.attackMetres>0)\n                   & (event_df.Result==\"Inaccurate\")\n                   & (event_df.subEventDescription.str.match('generic play'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateForwardPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# SuccessfulInterceptions ## when a player intercepts a play and makes a successful subsequent play\ndef success_intercept(event_df):\n    df = event_df[(event_df.Result == 'Accurate')\n                   & (event_df.subEventDescription.str.match('interception'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='SuccessfulInterceptions')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# CounterAttackInterceptions\ndef CounterAttackIntercepts(event_df):\n    df = event_df[(event_df.subEventDescription.str.match('counter_attack interception'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackIntercept')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# DangerousBallLostPassing\ndef dangerous_ball_lost(event_df):\n    df = event_df[(event_df.subEventName.str.contains(\"pass\")) \n                   & (event_df.subEventDescription.str.match('dangerous_ball_lost'))].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassLostDangerous')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Counter attack involvements\ndef CounterAttackInvolvements(event_df):\n    df = event_df[(event_df.subEventDescription.str.match('counter_attack')) \n                  & (event_df.Result == 'Accurate') ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='CounterAttackInvolvements')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Total Assists\ndef total_assists(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('assist')) \n                  & (event_df.Result == 'Accurate') ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='TotalAssists')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate Keypasses\ndef inacc_key_passes(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('key_pass')) \n                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateKeyPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Keypasses\ndef acc_keypasses(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('key_pass')) \n                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateKeyPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Through Passes\ndef acc_throughs(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('through')) \n                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateThroughPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n# Inaccurate Through Passes\ndef inacc_throughs(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('through')) \n                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateThroughPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Smart Passes \ndef acc_smart_passes(event_df):\n    df = event_df[(event_df.subEventName.str.match('Smart pass')) \n                  & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccurateSmartPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate Smart Passes \ndef inacc_smartPasses(event_df):\n    df = event_df[(event_df.subEventName.str.match('Smart pass')) \n                  & (event_df.Result == \"Inaccurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccurateSmartPasses')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Through passes into final third\ndef throughs_into_final(event_df):\n    df = event_df[(event_df.subEventDescription.str.contains('through')) \n                  & (event_df.xStart < 67 ) \n                  & (event_df.xEnd > 66 ) \n                 & (event_df.Result == \"Accurate\") ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccThroughsIntoFinalThird')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Passes into final third\ndef accPasses_into_final(event_df):\n    df = event_df[ ( event_df.subEventName.str.contains('pass'))\n        & (event_df.xStart < 67 ) \n                  & (event_df.xEnd > 66) \n                 & (event_df.Result == \"Accurate\")\n                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccPassesIntoFinalThird')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Passes into final third\ndef InaccPasses_into_final(event_df):\n    df = event_df[ ( event_df.subEventName.str.contains('pass'))\n        & (event_df.xStart < 67 ) \n                  & (event_df.xEnd > 66) \n                 & (event_df.Result == \"Inaccurate\")\n                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccPassesIntoFinalThird')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Accurate Passes within final third\ndef accPasses_within_finalThird(event_df):\n    df = event_df[ (event_df.subEventName.str.contains(\"pass\") )\n                   & (event_df.xStart > 66 ) \n                  & (event_df.xEnd > 66 ) \n                 & (event_df.Result == \"Accurate\")\n                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='AccPassesWithinFinalThird')\n#     df = transform_zonal(df, desiredName)\n    return df\n\n# Inaccurate Passes within final third   \ndef inaccPasses_within_finalThird(event_df):\n    df = event_df[ (event_df.subEventName.str.contains(\"pass\") )\n                   & (event_df.xStart > 66 ) \n                  & (event_df.xEnd > 66) \n                 & (event_df.Result == \"Inaccurate\")\n                & (event_df.Goal_Value != 1)].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='InaccPassesWithinFinalThird')\n#     df = transform_zonal(df, desiredName)\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shortLongPassRatio(event_df):\n    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n    df1 = event_df[(event_df.subEventName.str.contains('pass')) & ((event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n    df2 = event_df[(event_df.subEventName.str.contains('pass')) & (((event_df.attackMetres)>20) | (abs(event_df.lateralMetres>20))) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n    df1['shortLongPassRatio'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n#     df1 = transform_zonal(df, desiredName)\n    return df1\n\ndef longPassAccuracy(event_df):\n    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n    df1 = event_df[(event_df.subEventName.str.contains('pass')) & ((abs(event_df.attackMetres)>20) | abs(event_df.lateralMetres>20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n    df2 = event_df[(event_df.subEventName.str.contains('pass')) & ((abs(event_df.attackMetres)>20) | abs(event_df.lateralMetres>20)) ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n    df1['longPassAccuracy'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n#     df1 = transform_zonal(df, desiredName)\n    return df1\n\ndef shortPassAccuracy(event_df):\n    event_df['lateralMetres'] = event_df['yEnd']- event_df['yStart']\n    df1 = event_df[(event_df.subEventName.str.contains('pass')) & (abs(event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20)) & (event_df.Result==\"Accurate\")].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy1')\n    df2 = event_df[(event_df.subEventName.str.contains('pass'))& (abs(event_df.attackMetres)<20) & (abs(event_df.lateralMetres<20))  ].groupby(['playerId', 'matchId', \"ZoneStart\"]).size().reset_index(name='PassingAccuracy2')\n    df1 = pd.merge(df1,df2, how=\"left\", on=['playerId', 'matchId'])\n    df1['shortPassAccuracy'] = df1['PassingAccuracy1'] / df1['PassingAccuracy2']\n    df1.drop(['PassingAccuracy1', 'PassingAccuracy2'], inplace=True, axis =1)\n    return df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Events_England[\"ReceivingPlayer\"] = Events_England['playerId'].shift(-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Live match analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"liveTimes = []\nfor time in range(600, 6000, 600):\n    liveTimes.append(time)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### path = os.getcwd()\n# Events_England.to_csv(path+'/Events_England_processed')\n# Events_France.to_csv(path+'/Events_France_processed')\n# Events_Italy.to_csv(path+'/Events_Italy_processed')\n# Events_Spain.to_csv(path+'/Events_Spain_processed')\n# Events_Germany.to_csv(path+'/Events_Germany_processed')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Events_England_live = Events_England[Events_England.eventSec <= liveTime]\n# Events_France_live = Events_France[Events_France.eventSec <= liveTime]\n# Events_Italy_live = Events_Italy[Events_Italy.eventSec <= liveTime]\n# Events_Spain_live = Events_Spain[Events_Spain.eventSec <= liveTime]\n# Events_Germany_live = Events_Germany[Events_Germany.eventSec <= liveTime]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nPlayer_Aggs_live = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, position_df, how = 'right', on= 'playerId').sort_values('matchId')\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, p_refs, on = ['matchId', 'playerId'])\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, Teams[['teamId', 'name']], on = 'teamId')\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\nPlayer_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.homeTeamId, 'homeAway'] = \"home\"\nPlayer_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.awayTeamId, 'homeAway'] = \"away\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def playerGameTime_live(event_df, time):\n    df = event_df.groupby(['matchId','playerId'])['eventSec'].agg([ 'min']).reset_index()\n    df['liveTime'] = time\n    df['gameTime (min)'] = round((df['liveTime'] - df['min'])/60) # game time to the nearest minute\n    # Classify Match Result as W, L or D for teams\n    conditions = [\n        (df['gameTime (min)']  < 1),\n        (df['gameTime (min)'] > 0)\n        ]\n\n    # create a list of the values we want to assign for each condition\n    values = [0, df['gameTime (min)'].max()]\n\n    # create a new column and use np.select to assign values to it using our lists as arguments\n    df['gameTime (min)'] = np.select(conditions, values)\n    \n    df.drop(['liveTime', 'min'], inplace=True, axis=1)\n    return df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convenience function for event_df parsing\ndef parseEvent_df_live(func, new_feature, time, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live):\n    \n    aa = func(df_England_live)\n    aa = transform_zonal(aa, new_feature)\n    bb = func(df_France_live)\n    bb = transform_zonal(bb, new_feature)\n    cc = func(df_Italy_live)\n    cc = transform_zonal(cc, new_feature)\n    dd = func(df_Spain_live)\n    dd = transform_zonal(dd, new_feature)\n    ee = func(df_Germany_live)\n    ee = transform_zonal(ee, new_feature)\n    \n    \n    try:\n        return pd.concat([aa,bb,cc,dd,ee])\n    except:\n        return None\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for adding new feature column to Player_Aggs df\n\ndef alter_Player_Aggs_live(new_feature_function, new_feature, PA_df, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live):\n\n    df = parseEvent_df_live(new_feature_function, new_feature, time, df_England_live, df_France_live, df_Italy_live, df_Spain_live, df_Germany_live)\n\n    try:\n        PA_df = pd.merge(PA_df, df, how= 'left', on =['playerId', 'matchId'])\n    \n    except:\n        return PA_df\n    \n    return PA_df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs_live = Players[['shortName','Position', 'playerId','weight','height',  'foot' ]]\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, position_df, how = 'right', on= 'playerId').sort_values('matchId')\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, p_refs, on = ['matchId', 'playerId'])\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, Teams[['teamId', 'name']], on = 'teamId')\nPlayer_Aggs_live = pd.merge(Player_Aggs_live, Matches[['matchId', 'homeTeamId', 'awayTeamId']], on = 'matchId')\nPlayer_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.homeTeamId, 'homeAway'] = \"home\"\nPlayer_Aggs_live.loc[Player_Aggs_live.teamId == Player_Aggs_live.awayTeamId, 'homeAway'] = \"away\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# funkies = [AccBackwardMetres, InaccBackwardMetres, AccForwardMetres, InaccForwardMetres, SimulationFouls, Fouls, Clearances, AccLaunchMetres, InaccLaunchMetres, FreeKickCrossKey, FreeKickCrossAccuracy, dangerousOpponentHalfRecoveries, dangerousOwnHalfBallLost, dangerousDefDuelsLost, Saves, LeavingLine, SuccessAccelerations, FailedAccelerations, AccelDistance, AccelsIntoFinalThird, AccelsWithinFinalThird, RightFootCross, LeftFootCross, CrossKeyPasses, AccurateCrosses, InaccurateCrosses, AccCrossesBox, InaccCrossesBox, slidingTacklesWon, slidingTacklesLost, GroundDuelsWon, GroundDuelsLost, GroundDefAnticipations, GroundLooseBallsWon, GroundLooseBallsLost, GroundAttackDuelsWon, GroundAttackDuelsLost, OffTouchesBox, ShotsOnTarget, ShotsOffTarget, shot_opportunities, accFreeKicks, InaccFreeKicks, PenaltyNotGoal, AerialDuelsWon, AerialDuelsLost, inaccPasses_within_finalThird, accPasses_within_finalThird, accPasses_into_final, InaccPasses_into_final, throughs_into_final, inacc_smartPasses, acc_smart_passes, inacc_throughs, acc_throughs, acc_keypasses, inacc_key_passes, CounterAttackInvolvements, dangerous_ball_lost, CounterAttackIntercepts, success_intercept, inacc_forward_passes, acc_forward_pass, corner_assists, corner_opportunity, corner_success, corner_fail]\n# var_noms = [\"AccBackMetres\",  \"InaccBackMetres\",  \"AccForwardMetres\",  \"InaccForwardMetres\",  \"SimulationFouls\",  \"FoulsCommited\",  \"Clearances\",  \"AccLaunchMetres\",  \"InaccLaunchMetres\",  \"FKKeyCross\",  \"AccFreeKickCrosses\",  \"dangerousOpponentHalfRecoveries\",  \"dangerousOwnHalfBallLost\",  \"dangerousDefDuelsLost\",  \"GkSaves\", \"GKLeavingLineInstance\",  \"SuccessfulAccels\",  \"FailedAccels\",  \"CumAccelerationDist\",  \"AccelsDistIntoFinal3rd\",  \"AccelsDistWithinFinal3rd\",  \"RightFootCross\",  \"LeftFootCross\",  \"CrossKeyPass\",  \"AccCrosses\",  \"InaccCrosses\",  \"AccCrossesIntoBox\",  \"InaccCrossesIntoBox\",  \"SlidingTacklesWon\",  \"SlidingTacklesLost\",  \"GroundDefDuelsWon\",  \"GroundDefDuelsLost\",  \"DefensiveAnticipations\",  \"GroundLooseBallsWon\",  \"GroundLooseBallsLost\",  \"GroundAttackDuelsWon\",  \"GroundAttackDuelsLost\",  \"OffensiveTouchesBox\",  \"ShotsOnTarget\",  \"ShotsOffTarget\",  \"ShotOpportunities\",  \"FreeKickShotAcc\",  \"FreeKickShotInacc\",  \"PenaltyNotScored\",  \"AerialDuelsWon\",  \"AerialDuelsLost\",  \"InaccPassesWithinFinalThird\",  \"AccPassesWithinFinalThird\",  \"AccPassesIntoFinalThird\",  \"InaccPassesIntoFinalThird\",  \"AccThroughsIntoFinalThird\",  \"InaccurateSmartPasses\",  \"AccurateSmartPasses\",  \"InaccurateThroughPasses\",  \"AccurateThroughPasses\",  \"AccurateKeyPasses\",  \"InaccurateKeyPasses\",  \"CounterAttackInvolvements\",  \"PassLostDangerous\",  \"CounterAttackIntercept\",  \"SuccessfulInterceptions\",  \"InaccurateForwardPasses\",  \"AccurateForwardPasses\",  \"CornerAssists\",  \"CornerOpportunitiesCreated\",  \"SuccessfulCorners\",  \"FailedCorners\"]\n    \n    \n# for indx in range(len(funkies)):\n#     Player_Aggs2 = alter_Player_Aggs(funkies[indx], var_noms[indx], Player_Aggs2)\n#     Player_Aggs2 = Player_Aggs2.drop_duplicates()\n#     remove_col = [col for col in Player_Aggs2 if col.endswith(\"_0\")]\n#     if remove_col:\n#         Player_Aggs2.drop(columns = remove_col, inplace=True, axis=1)\n\n# Player_Aggs2 = Player_Aggs2.loc[:, (Player_Aggs2 != 0).any(axis=0)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Live Match # # #\n\ndef get_live_players(player_aggs_live, time):\n    \n    # derive gameTime per player and store in summary table\n    a = playerGameTime_live(Events_England, time)\n    b = playerGameTime_live(Events_France, time)\n    c = playerGameTime_live(Events_Italy, time)\n    d = playerGameTime_live(Events_Spain, time)\n    e = playerGameTime_live(Events_Germany, time)\n\n    playingTime_live = pd.concat([a,b,c,d,e])\n\n    player_aggs_live = pd.merge(player_aggs_live, playingTime_live, how = 'left', on = ['playerId', 'matchId'])\n\n    funkies = [AccBackwardMetres, InaccBackwardMetres, AccForwardMetres, InaccForwardMetres, SimulationFouls, Fouls, Clearances, AccLaunchMetres, InaccLaunchMetres, FreeKickCrossKey, FreeKickCrossAccuracy, dangerousOpponentHalfRecoveries, dangerousOwnHalfBallLost, dangerousDefDuelsLost, Saves, LeavingLine, SuccessAccelerations, FailedAccelerations, AccelDistance, AccelsIntoFinalThird, AccelsWithinFinalThird, RightFootCross, LeftFootCross, CrossKeyPasses, AccurateCrosses, InaccurateCrosses, AccCrossesBox, InaccCrossesBox, slidingTacklesWon, slidingTacklesLost, GroundDuelsWon, GroundDuelsLost, GroundDefAnticipations, GroundLooseBallsWon, GroundLooseBallsLost, GroundAttackDuelsWon, GroundAttackDuelsLost, OffTouchesBox, ShotsOnTarget, ShotsOffTarget, shot_opportunities, accFreeKicks, InaccFreeKicks, PenaltyNotGoal, AerialDuelsWon, AerialDuelsLost, inaccPasses_within_finalThird, accPasses_within_finalThird, accPasses_into_final, InaccPasses_into_final, throughs_into_final, inacc_smartPasses, acc_smart_passes, inacc_throughs, acc_throughs, acc_keypasses, inacc_key_passes, CounterAttackInvolvements, dangerous_ball_lost, CounterAttackIntercepts, success_intercept, inacc_forward_passes, acc_forward_pass, corner_assists, corner_opportunity, corner_success, corner_fail]\n    var_noms = [\"AccBackMetres\",  \"InaccBackMetres\",  \"AccForwardMetres\",  \"InaccForwardMetres\",  \"SimulationFouls\",  \"FoulsCommited\",  \"Clearances\",  \"AccLaunchMetres\",  \"InaccLaunchMetres\",  \"FKKeyCross\",  \"AccFreeKickCrosses\",  \"dangerousOpponentHalfRecoveries\",  \"dangerousOwnHalfBallLost\",  \"dangerousDefDuelsLost\",  \"GkSaves\", \"GKLeavingLineInstance\",  \"SuccessfulAccels\",  \"FailedAccels\",  \"CumAccelerationDist\",  \"AccelsDistIntoFinal3rd\",  \"AccelsDistWithinFinal3rd\",  \"RightFootCross\",  \"LeftFootCross\",  \"CrossKeyPass\",  \"AccCrosses\",  \"InaccCrosses\",  \"AccCrossesIntoBox\",  \"InaccCrossesIntoBox\",  \"SlidingTacklesWon\",  \"SlidingTacklesLost\",  \"GroundDefDuelsWon\",  \"GroundDefDuelsLost\",  \"DefensiveAnticipations\",  \"GroundLooseBallsWon\",  \"GroundLooseBallsLost\",  \"GroundAttackDuelsWon\",  \"GroundAttackDuelsLost\",  \"OffensiveTouchesBox\",  \"ShotsOnTarget\",  \"ShotsOffTarget\",  \"ShotOpportunities\",  \"FreeKickShotAcc\",  \"FreeKickShotInacc\",  \"PenaltyNotScored\",  \"AerialDuelsWon\",  \"AerialDuelsLost\",  \"InaccPassesWithinFinalThird\",  \"AccPassesWithinFinalThird\",  \"AccPassesIntoFinalThird\",  \"InaccPassesIntoFinalThird\",  \"AccThroughsIntoFinalThird\",  \"InaccurateSmartPasses\",  \"AccurateSmartPasses\",  \"InaccurateThroughPasses\",  \"AccurateThroughPasses\",  \"AccurateKeyPasses\",  \"InaccurateKeyPasses\",  \"CounterAttackInvolvements\",  \"PassLostDangerous\",  \"CounterAttackIntercept\",  \"SuccessfulInterceptions\",  \"InaccurateForwardPasses\",  \"AccurateForwardPasses\",  \"CornerAssists\",  \"CornerOpportunitiesCreated\",  \"SuccessfulCorners\",  \"FailedCorners\"]\n    \n    Events_England_live = Events_England[Events_England.eventSec <= time]\n    Events_France_live = Events_France[Events_France.eventSec <= time]\n    Events_Italy_live = Events_Italy[Events_Italy.eventSec <= time]\n    Events_Spain_live = Events_Spain[Events_Spain.eventSec <= time]\n    Events_Germany_live = Events_Germany[Events_Germany.eventSec <= time]\n    \n    for indx in range(len(funkies)):\n        player_aggs_live = alter_Player_Aggs_live(funkies[indx], var_noms[indx], player_aggs_live, Events_England_live, Events_France_live, Events_Italy_live, Events_Spain_live, Events_Germany_live)\n        player_aggs_live = player_aggs_live.drop_duplicates()\n        remove_col = [col for col in player_aggs_live if col.endswith(\"_0\")]\n        if remove_col:\n            player_aggs_live.drop(columns = remove_col, inplace=True, axis=1)  \n\n    player_aggs_live.iloc[:,15:] = player_aggs_live.iloc[:,15:].fillna(0)\n    player_aggs_live.iloc[:,15:] = player_aggs_live.iloc[:,15:].div(player_aggs_live[\"gameTime (min)\"], axis =0).fillna(0)*90\n    player_aggs_live = player_aggs_live.loc[:, (player_aggs_live != 0).any(axis=0)]\n    \n    return player_aggs_live\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Player_Aggs_live10 = get_live_players(Player_Aggs_live, 600)\n# Player_Aggs_live20 = get_live_players(Player_Aggs_live, 1200)\n# Player_Aggs_live30 = get_live_players(Player_Aggs_live, 1800)\n# Player_Aggs_live40 = get_live_players(Player_Aggs_live, 2400)\n# Player_Aggs_live50 = get_live_players(Player_Aggs_live, 3000)\n# Player_Aggs_live60 = get_live_players(Player_Aggs_live, 3600)\n# Player_Aggs_live70 = get_live_players(Player_Aggs_live, 4200)\n# Player_Aggs_live80 = get_live_players(Player_Aggs_live, 4800)\n# Player_Aggs_live90 = get_live_players(Player_Aggs_live, 5400)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.chdir('/group/interns202010/jmakins/Data/events')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/youwot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import zipfile\n# with zipfile.ZipFile('/kaggle/input/youwot', 'r') as zip_ref:\n#     zip_ref.extractall('/kaggle/input/youwot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# path = os.getcwd()\n\n# Player_Aggs_live10.to_csv(path+'/Player_Aggs_live10')\n# Player_Aggs_live20.to_csv(path+'/Player_Aggs_live20')\n# Player_Aggs_live30.to_csv(path+'/Player_Aggs_live30')\n# Player_Aggs_live40.to_csv(path+'/Player_Aggs_live40')\n# Player_Aggs_live50.to_csv(path+'/Player_Aggs_live50')\n# Player_Aggs_live60.to_csv(path+'/Player_Aggs_live60')\n# Player_Aggs_live70.to_csv(path+'/Player_Aggs_live70')\n# Player_Aggs_live80.to_csv(path+'/Player_Aggs_live80')\n# Player_Aggs_live90.to_csv(path+'/Player_Aggs_live90')\n\n# Player_Aggs_live10 = pd.read_csv('Player_Aggs_live10')\n# Player_Aggs_live10.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live20= pd.read_csv('Player_Aggs_live20')\n# Player_Aggs_live20.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live30= pd.read_csv('Player_Aggs_live30')\n# Player_Aggs_live30.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live40= pd.read_csv('Player_Aggs_live40')\n# Player_Aggs_live40.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live50= pd.read_csv('Player_Aggs_live50')\n# Player_Aggs_live50.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live60= pd.read_csv('Player_Aggs_live60')\n# Player_Aggs_live60.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live70= pd.read_csv('Player_Aggs_live70')\n# Player_Aggs_live70.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live80= pd.read_csv('Player_Aggs_live80')\n# Player_Aggs_live80.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n# Player_Aggs_live90= pd.read_csv('Player_Aggs_live90')\n# Player_Aggs_live90.drop([\"Unnamed: 0\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import auc\nfrom sklearn.cluster import KMeans \nfrom sklearn import metrics \nfrom scipy.spatial.distance import cdist \nimport matplotlib.pyplot as plt  \nimport matplotlib.patches as patches\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.utils import shuffle\nfrom sklearn import metrics\nfrom random import seed\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del Player_Aggs_live10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs_live90= pd.read_csv('Player_Aggs_live90')\nPlayer_Aggs_live90.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n\n# Events_England = pd.read_csv('eventsEvents_England_processed')\n# Events_Italy = pd.read_csv('eventsEvents_Italy_processed')\n# Events_Germany = pd.read_csv('eventsEvents_Germany_processed')\n# Events_France = pd.read_csv('eventsEvents_France_processed')\n# Events_Spain = pd.read_csv('eventsEvents_Spain_processed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### fDNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Matches_df_fDNN(TAM):\n    df2 = TAM.groupby('matchId').agg(list).reset_index()\n    df2.drop([\"Result\",\"homeTeamId\", \"awayTeamId\", \"height\", \"weight\", 'playerId', \"xStart\", \"yStart\", \"gameTime (min)\"], inplace=True, axis=1)\n\n    df4 = pd.concat([df2, pd.DataFrame(df2['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n    df4.drop([\"teamId\"], inplace=True, axis = 1)\n    result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n\n\n    df3 = result.iloc[:,-4:]\n    for var in list(result.columns)[1:-4]:\n\n        df3 = pd.concat([df3, pd.DataFrame(result[var].to_list(), columns=[\"1_\" + var, \"2_\" + var])], axis=1, sort = False)\n\n        # Correctly apply allocate home and away aggregate statistics to correct teams\n        df3['home'+var] = (\n            np.select(\n                condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n                choicelist=[df3[\"1_\" + var], df3[\"2_\" + var]]))\n\n        df3['away'+var] = (\n            np.select(\n                condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n                choicelist=[df3[\"1_\" + var], df3[\"2_\" + var]]))\n\n        # # drop useless columns that have been replaced\n        df3.drop([ \"1_\" + var, \"2_\" + var], inplace = True, axis = 1 )\n\n    df3 = pd.concat([result[['matchId']],df3], axis=1)\n    df3 = pd.merge(df3, Matches[[\"matchId\", \"Result\"]], how =\"inner\", on='matchId')\n    df3.drop([\"team1\", \"team2\"], axis=1, inplace=True)\n\n    return df3\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Team_Aggs_Matches = Player_Aggs_live90.groupby(['matchId', 'teamId' ]).sum().reset_index()\nTeam_Aggs_Matches = pd.merge(Team_Aggs_Matches, Matches[['matchId', \"Result\"]], how = 'left', on = 'matchId' )\nresult = Matches_df_fDNN(Team_Aggs_Matches)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = result.loc[:, ~result.columns.isin([\"Result\",'teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\ny_all = result[\"Result\"].values\nX_all = X_all.replace([np.inf, -np.inf], np.nan)\nX_all = X_all.fillna(X_all.mean())\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_validate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclf = RandomForestClassifier(n_estimators = 500, random_state=123, max_depth = 5)\nclf.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [-1,0,1]\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred, labels = labels))\nprint('accuracy score: {0:.4f}'.format(accuracy_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(y_test, y_pred, rownames=['Actual Result'], colnames=['Predicted Result']))\nclass_name = list(set(y_test))\nprint(class_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nmpl.rcParams['figure.figsize'] = (16, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feature_importance = pd.DataFrame(clf.feature_importances_, index=X_all.columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feature_importance[0:20].plot(kind='bar')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## DNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_trainD, X_testD, y_trainD, y_testD = train_test_split(X_train, y_train, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scaler = StandardScaler().fit(X_trainD)\n\n# X_trainD = scaler.transform(X_trainD)\n\n# X_testD = scaler.transform(X_testD)\n\n# X_testD2 = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Define per-fold score containers\n# acc_per_fold = []\n# loss_per_fold = []\n\n# kfold = KFold(n_splits=5, shuffle=True)\n\n# fold_no=1\n\n# for train, test in kfold.split(X_trainD, y_trainD):\n    \n#     dnn = Sequential()\n#     #dnn.add(Flatten(input_shape=(500,3)))\n#     #dnn.add(Dense(512, activation='relu',kernel_initializer = 'he_normal'))\n#     #dnn.add(Dropout(0.3))\n#     dnn.add(Dense(256, activation='relu', kernel_initializer = 'he_normal' ,input_shape=(X_testD2.shape[1],)))\n#     dnn.add(Dropout(0.4))\n#     dnn.add(Dense(128, activation='relu',kernel_initializer = 'he_normal'))\n#     dnn.add(Dropout(0.4))\n#     dnn.add(Dense(64, activation='relu',kernel_initializer = 'he_normal'))\n#     dnn.add(Dropout(0.4))\n#     dnn.add(Dense(1, activation='sigmoid',kernel_initializer = 'he_normal'))\n#     #optim = keras.optimizers.SGD(lr=0.01, momentum=0.975, decay=2e-06, nesterov=True)\n#     opt = keras.optimizers.Adam(learning_rate=0.00000001)\n\n\n#     dnn.compile(loss='categorical_crossentropy',\n#     optimizer=opt, metrics=['accuracy'])\n\n\n#     #history = model.fit(X_train2, y_train2,\n#     #batch_size = 32, epochs = 1,  verbose = 2)#, validation_data= (x_valid, y_valid))\n\n#     history = dnn.fit(X_trainD[train], y_trainD[train], validation_data = (X_trainD[test], y_trainD[test]), epochs=2500, batch_size=32, verbose =2)\n\n#     # batchsize 256\n#     #lr 0.00001, 0.0001\n\n#     print(dnn.summary())\n\n#     # Generate generalization metrics\n#     scores = model.evaluate(X_trainD[test], y_trainD[test], verbose=0)\n#     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n#     acc_per_fold.append(scores[1] * 100)\n#     loss_per_fold.append(scores[0])\n#     # Increase fold number\n#     fold_no = fold_no + 1\n\n# # score = model.evaluate(X_test2, y_test2, verbose=0)\n# # print('Test loss:', score[0])\n# # print('Test top 1 accuracy:', score[1])\n\n# # == Provide average scores ==\n# print('------------------------------------------------------------------------')\n# print('Score per fold')\n# for i in range(0, len(acc_per_fold)):\n#     print('------------------------------------------------------------------------')\n#     print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n# print('------------------------------------------------------------------------')\n# print('Average scores for all folds:')\n# print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n# print(f'> Loss: {np.mean(loss_per_fold)}')\n# print('------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# y_pred = dnn.predict(X_testD2)\n# #Converting predictions to label\n# pred = list()\n# for i in range(len(y_pred)):\n#     pred.append(np.argmax(y_pred[i]))\n# # #Converting one hot encoded test label to label\n# # test = list()\n# # for i in range(len(y_test2)):\n# #     test.append(np.argmax(y_test[i]))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a = accuracy_score(pred,y_test)\n# print('Accuracy is:', a*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## fdnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test2 = [tree.predict(X_test) for tree in clf.estimators_]\nX_test2 = np.transpose(X_test2)\nX_train2 = [tree.predict(X_train) for tree in clf.estimators_]\nX_train2 = np.transpose(X_train2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x_total = [tree.predict(result) for tree in clf.estimators_]\n# x_total = np.transpose(x_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def X_transform(X):\n    df = []  \n    for sample in X:\n        s = []\n        for feature in sample:\n            if feature == 2:\n                s.append([0, 0, 1])\n            elif feature == 1:\n                s.append([0, 1, 0])\n            else:\n                s.append([1, 0, 0])\n        df.append(s)\n    df = np.array(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2 = X_transform(X_train2)\nX_test2 = X_transform(X_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2.shape\nX_test2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## one-hot encode the labels\ndef y_transform(Y):\n    df = []\n    for l in Y:\n        if l == 1:\n            df.append([0, 0, 1])\n        elif l == 0:\n            df.append([0, 1, 0])\n        else:\n            df.append([1, 0, 0])\n    df = np.array(df,dtype=int)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train2 = y_transform(y_train)\ny_test2 = y_transform(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train2.shape)\nprint(y_test2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train2, X_test3, y_train2, y_test3 = train_test_split(X_train2, y_train2, test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train2.shape)\nprint(X_train2.shape)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Keras DNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model\n\n# Define per-fold score containers\nacc_per_fold = []\nloss_per_fold = []\n\nkfold = KFold(n_splits=3, shuffle=True)\n\nfold_no=1\n\nfor train, test in kfold.split(X_train2, y_train2):\n\n    model = Sequential()\n    model.add(Flatten(input_shape=(500,3)))\n    model.add(Dense(256, activation='relu', kernel_initializer = 'he_normal' ,input_shape=(500*3,)))\n    model.add(Dropout(0.4))\n    model.add(Dense(128, activation='relu',kernel_initializer = 'he_normal'))\n    model.add(Dropout(0.4))\n    model.add(Dense(64, activation='relu',kernel_initializer = 'he_normal'))\n    model.add(Dropout(0.4))\n    model.add(Dense(3, activation='softmax',kernel_initializer = 'he_normal'))\n    opt = keras.optimizers.Adam(learning_rate=0.000001)\n\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\n    #history = model.fit(X_train2, y_train2,\n    #batch_size = 32, epochs = 1,  verbose = 2)#, validation_data= (x_valid, y_valid))\n\n    history = model.fit(X_train2[train], y_train2[train], validation_data = (X_train2[test], y_train2[test]), epochs=2000, batch_size=32, verbose =2)\n\n    # batchsize 256\n    #lr 0.00001, 0.0001\n\n    print(model.summary())\n    \n    # Generate generalization metrics\n    scores = model.evaluate(X_train2[test], y_train2[test], verbose=0)\n    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n    acc_per_fold.append(scores[1] * 100)\n    loss_per_fold.append(scores[0])\n    # Increase fold number\n    fold_no = fold_no + 1\n\n# score = model.evaluate(X_test2, y_test2, verbose=0)\n# print('Test loss:', score[0])\n# print('Test top 1 accuracy:', score[1])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# == Provide average scores ==\nprint('------------------------------------------------------------------------')\nprint('Score per fold')\nfor i in range(0, len(acc_per_fold)):\n    print('------------------------------------------------------------------------')\n    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\nprint('------------------------------------------------------------------------')\nprint('Average scores for all folds:')\nprint(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\nprint(f'> Loss: {np.mean(loss_per_fold)}')\nprint('------------------------------------------------------------------------')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(X_test2)\n#Converting predictions to label\npred = list()\nfor i in range(len(y_pred)):\n    pred.append(np.argmax(y_pred[i]))\n#Converting one hot encoded test label to label\ntest = list()\nfor i in range(len(y_test2)):\n    test.append(np.argmax(y_test2[i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = accuracy_score(pred,test)\nprint('Accuracy is:', a*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(pred)):\n    if pred[i]==2:\n        pred[i] = 1\n    elif pred[i]==0:\n        pred[i]= -1\n    else:\n        pred[i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(test)):\n    if test[i]==2:\n        test[i] = 1\n    elif test[i]==0:\n        test[i]= -1\n    else:\n        test[i]=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, pred)\nimport seaborn as sns\nmpl.rcParams.update(mpl.rcParamsDefault)\nplt.rcParams['font.size'] = 14\nfig, ax = plt.subplots(1)\nx_axis_labels,y_axis_labels = [\"Loss\", \"Draw\", \"Win\"], [\"Loss\", \"Draw\", \"Win\"]\n#sns.color_palette(\"magma\")\nsns.heatmap(cf_matrix, annot=True, fmt=\"d\", xticklabels=x_axis_labels, yticklabels=y_axis_labels, center=50, linecolor=\"black\", cmap='flag', linewidths=0.2, annot_kws={'size':20},cbar=False), #,cmap=\"PiYG\")\nplt.xlabel(\"Predicted Result\",  color = \"white\")\nplt.ylabel(\"Actual Result\",  color = \"white\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"collections.Counter(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [-1,0,1]\n\nprint(classification_report(test, pred, labels = labels,target_names=['Loss', 'Draw', 'Win']))\nprint('accuracy score: {0:.4f}'.format(accuracy_score(test,pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pd.crosstab(np.array(test), np.array(pred), rownames=['Actual Result'], colnames=['Predicted Result']))\nclass_name = list(set(test))\nprint(class_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss']) \nplt.title('Model loss') \nplt.ylabel('Loss') \nplt.xlabel('Epoch') \nplt.legend(['Train', 'Test'], loc='upper left') \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###### XGBoost DNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0, 0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5, 6, 7, 8],\n        'learning_rate': [0.0001,0.001, 0.01, 0.02,0.1, 0.2, 0.3],\n        'n_estimators': [100,200,500,1000]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nfrom datetime import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_comb = 5\n# folds = 5\n\n# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n\n# random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='accuracy', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n\n# # Here we go\n# start_time = timer(None) # timing starts from this point for \"start_time\" variable\n# random_search.fit(X_train, y_train)\n# timer(start_time) # timing ends here for \"start_time\" variable\n\n# # xgb.fit(X_train, y_train)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print('\\n All results:')\n# print(random_search.cv_results_)\n# print('\\n Best estimator:')\n# print(random_search.best_estimator_)\n# print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n# print(random_search.best_score_ * 2 - 1)\n# print('\\n Best hyperparameters:')\n# print(random_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### CREATE XGB WITH OPTIMIZED PARAMS\n# Best hyperparameters: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 7, 'learning_rate': 0.2, 'gamma': 1.5, 'colsample_bytree': 0.8}\n\nxgb = XGBClassifier(features_names=X_all.columns, gamma=1.5, n_estimators =500, max_depth=7, min_child_weight=5)\nxgb.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# feat_imp = pd.Series(xgb.booster().get_fscore()).sort_values(ascending=False)\n# feat_imp.plot(kind='bar', title='Feature Importances')57.1\n# plt.ylabel('Feature Importance Score')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions for test data\ny_pred = xgb.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\n# evaluate predictions\naccuracy = accuracy_score(y_test, predictions)\nprint(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\n# plot feature importance\nplot_importance(xgb, max_num_features=25, ylabel=\"Features\")\nplt.figure(figsize=(5,5))\nfig.set_size_inches(6.5, 4.5, forward=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_tree\n# plot single tree\nplot_tree(xgb, num_trees=1, rankdir='LR')\n#plt.rcParams['figure.figsize'] = [50, 20]\nmpl.rcParams.update(mpl.rcParamsDefault)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BREAK sfkldfkjsdkfl asap rocky","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Result visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"names = [\"RF\", \"fDNN\", \"xgboost\"]\nminutes = [10,20,30,40,50,60,70,80,90]\nx = list(range(9))\nfdnn = []\nxb = []\nrf = []\n\naccuracies = [47.54, 47.55, 46.17, 50.55, 59.56, 46.72, 50.82, 54.10, 51.37, 51.91, 57.377, 57.10, 51.64, 54.92, 59.02, 53.01, 59.56, 52.8, 52.19, 57.38, 59.84, 53.55, 60.11, 63.93, 53.55, 64.481, 64.75]\nfor i in range(0,27,3):\n    try:\n        rf.append(accuracies[i])\n        fdnn.append(accuracies[i+1])\n        xb.append(accuracies[i+2])\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'RF': rf, \"fDNN\": fdnn, \"XGBoost\": xb, \"Minutes\": minutes})\n\n#plt.style.use('fivethirtyeight')\n#plt.style.use('seaborn-darkgrid')\n#my_dpi=96\nfig = plt.figure(figsize=(480/my_dpi, 480/my_dpi), dpi=my_dpi)\nfig.patch.set_facecolor('#241C24')\n\n\n# create a color palette\npalette = plt.get_cmap('Dark2')\n \n# multiple line plot\n\nplt.plot(df['Minutes'], df[\"RF\"], marker='', color=\"#fbc5ff\", linewidth=2, alpha=0.8, label=\"RF\")\nplt.plot(df['Minutes'], df[\"XGBoost\"], marker='', color=\"#357ffd\", linewidth=2, alpha=0.4, label=\"XGBoost\")\nplt.plot(df['Minutes'], df[\"fDNN\"], marker='', color=\"#c197d2\", linewidth=4, alpha=1, label=\"fDNN\")\n\n# Add legend\nplt.legend(loc=2, ncol=2)\n    \n# Change xlim\nplt.xlim(0,100)\n \n# Add titles\nplt.title(\"fDNN vs Random Forest and XGBoost\", loc='left', fontsize=16, fontweight=0, color='white')\nplt.xlabel(\"Minutes\", color = 'white', size = 14)\nplt.ylabel(\"Accuracy Score\", color = 'white', size=14)\nplt.xticks(color=\"white\")\nplt.yticks(color=\"white\")\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Team Tactics and Automated Subs / Formation Shifts"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nfrom numpy import mean\nfrom numpy import std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# udfs ----\n\n# function for creating a feature importance dataframe\ndef imp_df(column_names, importances):\n    df = pd.DataFrame({'feature': column_names,\n                       'feature_importance': importances}) \\\n           .sort_values('feature_importance', ascending = False) \\\n           .reset_index(drop = True)\n    return df\n\n# plotting a feature importance dataframe (horizontal barchart)\ndef var_imp_plot(imp_df, title):\n    imp_df.columns = ['feature', 'feature_importance']\n    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, orient = 'h', color = 'royalblue') \\\n       .set_title(title, fontsize = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"team_tactics = Player_Aggs_live90.groupby(['matchId', 'teamId']).sum().reset_index()\nteam_tactics.drop([\"playerId\", 'weight', 'height', 'xStart', 'yStart', 'homeTeamId', 'awayTeamId', 'gameTime (min)' ], axis = 1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def team_result(team_df):\n    \n    df = pd.merge(team_df, Matches[[\"homeTeamId\", \"awayTeamId\",\"matchId\", \"Result\"]], how = \"left\", on = [\"matchId\"])\n    \n    # Classify Match W, L or D for a team\n    conditions = [\n        ((df['homeTeamId'] == df.teamId) &(df.Result==1)),\n        ((df['homeTeamId'] == df.teamId)&(df.Result==0)),\n        ((df['homeTeamId'] == df.teamId)&(df.Result==-1)),\n        ((df['awayTeamId'] == df.teamId)&(df.Result==1)),\n        ((df['awayTeamId'] == df.teamId)&(df.Result==0)),\n        ((df['awayTeamId'] == df.teamId)&(df.Result==-1))\n        ]\n\n    # create a list of the values we want to assign for each condition\n    values = [1,0,-1,-1,0,1]\n\n    # create a new column and use np.select to assign values to it using our lists as arguments\n    df['result'] = np.select(conditions, values)\n    df.drop([\"Result\"], axis=1,inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = team_result(team_tactics)\n\ndf = df.replace([np.inf, -np.inf], np.nan)\ndf = df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.DataFrame(None, columns = team_tactics.columns)\n\n# for team in teams:\n#     test = team_tactics[team_tactics.teamId == team]\n#     data = team_result(team, test)\n#     df = df.append(data, ignore_index=True)\n\n# df = df.replace([np.inf, -np.inf], np.nan)\n# df = df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.loc[:, (df != 0).any(axis=0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = df.iloc[:,2:-1]\ny_all = df.result.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 500, random_state=123)\nrf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Determing player ratings for feature importance\n\ndf1 = Player_Aggs_live90.iloc[:,:15]\ndf2 = Player_Aggs_live90.iloc[:,15:]\ndf2 = df2.replace([np.inf, -np.inf], np.nan)\ndf2 = df2.fillna(0)\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(df2.values)\ndf2 = pd.DataFrame(x_scaled, columns = df2.columns)\n\nbase_imp = imp_df(df2.columns, rf.feature_importances_)\nxxx = base_imp.transpose()\nxxx.columns = xxx.iloc[0]\nxxx = xxx.drop(xxx.index[[0]])\nxxx = xxx.reindex(sorted(xxx.columns), axis=1)\ndf2 = df2.reindex(sorted(df2.columns), axis=1)\ndf2 = df2.multiply(xxx.values)\nnegatives = df2.filter(regex='Inacc|Lost|Fouls|Fail|Not|Leaving').columns\ndf2[negatives] = df2[negatives].multiply(-1)\ndf2[\"sum\"] = df2.iloc[:,:-1].sum(axis=1)\ndf2 = pd.concat([df1, df2], axis=1)\ndf2 = pd.merge(df2, df[[\"matchId\", 'teamId', \"result\"]], on =['matchId', \"teamId\"], how = 'left' )\n#df2 = df2.loc[:, (df2 != 0).any(axis=0)]\ndf2['playerRatings']=  np.where(df2['gameTime (min)'] ==0, 0, df2['sum'])\ndf2['playerRatings'] = df2['playerRatings'].multiply(94 / float(df2.playerRatings.nlargest(5)[-1:]))\ndf2['playerRatings'] = np.where(df2['playerRatings'] > 94.0, 94, df2['playerRatings'])\ndf2.drop([\"sum\"], axis=1, inplace=True)\ncollections.Counter(df2.sort_values(\"playerRatings\", ascending=False).iloc[0:100,:].Position)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inspecting player performance in a specific match for automated tactical sub recommendations (underperforming players)\ndf2[df2.matchId==2499725].sort_values(\"playerRatings\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_values = df2.sort_values(\"playerRatings\", ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = player_values.groupby([\"shortName\", 'playerId', \"teamId\", \"Position\"]).sum().reset_index().sort_values(\"playerRatings\", ascending=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = ['purple','#c197d2','pink'] #navy\nfig =plt.figure()\nax = test.head(100).groupby('Position')[\"playerRatings\"].nunique().plot(kind='bar',  color=colors, )\nax.patch.set_facecolor('#241C24')\nfig.patch.set_facecolor('#241C24')\nax.tick_params(axis='x', colors='white',size =16 )\nax.tick_params(axis='y', colors='white', size=16)\nplt.ylabel(\"Number of Players\", color = \"white\", size = 12)\nplt.xlabel(\"Positions\", color = \"white\", size=12)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"PR_perMatch\"] = 100*test[\"playerRatings\"] / test[\"gameTime (min)\"] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test.iloc[2:3,0:1] =  \"M.Hamsik\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"PR_perMatch\"] = test[\"PR_perMatch\"].multiply(94 / float(test.PR_perMatch.max()))# normalize player ratings per match\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    test = test.rename(columns= {\"shortName\": \"Name\"})\nexcept:\n    pass\n\ntry:\n    test = test.rename(columns= {\"gameTime (min)\": \"Mins Played\"})\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sort_values(\"playerRatings\", ascending=False).round(1)[[\"Name\", \"Position\", \"Mins Played\", \"playerRatings\"]].head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"# inspecting feature importance from random forest\ndf_feature_importance = pd.DataFrame(rf.feature_importances_, index=df2.iloc[:,15:-2].columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(pd.Series(rf.feature_importances_, index=X_train.columns)\n   .nlargest(4)\n   .plot(kind='barh')) \n#e6b32d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.patch.set_facecolor('blue')\nfig.patch.set_alpha(0.6)\n\nfeat_imp_data = sorted(list(zip(X_train.columns, rf.feature_importances_)), key=lambda datum: datum[1], reverse=False)[0:10]\n\n# Unzip the values and labels\nwidths = [x[1] for x in feat_imp_data]\nyticks = [x[0] for x in feat_imp_data]\n\nn_features = int(X_train.shape[1])\n\nax = fig.add_subplot(111)\nax.patch.set_facecolor('orange')\nax.patch.set_alpha(1.0)\n\nplt.barh(range(n_features),widths, align='center')\nplt.yticks(np.arange(n_features), X_train.columns) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_max_scaler = preprocessing.MinMaxScaler()\n# x_scaled = min_max_scaler.fit_transform(X_all.values)\n# df = pd.DataFrame(x_scaled, columns = X_all.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a, b =X_train.columns, df2.columns\n(a | b).difference(a & b)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Tactical sub in"},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs_live90[Player_Aggs_live90.teamId==1612].matchId.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### univariate regression\n##### Identify opposition weakness in a match\n##### Identify optimal player for tactical sub to replace our weak player and exploit their weakness\n##### Identify formation that gives opposition toughest time (label formations below)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# identify our weakest player\ndf2[(df2.matchId==2499773) & (df2.teamId==1612) &(df2.Position!=\"GKP\") &(df2.playerRatings!=0)].sort_values(\"playerRatings\", ascending=False).iloc[-1:,:]\n\n# identify opposition weakness in style and tactics\n\n\n# replace with most similar player or exploitative player\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.groupby(['matchId', 'teamId', \"result\"]).sum().reset_index().head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calcualte team performance ratings \n# df2['teamRatings'] = df2['playerRatings'].multiply(df2['gameTime (min)'])\n# team_perf = df2.groupby(['matchId', 'teamId']).sum().reset_index()\n# team_perf.drop([\"Result\",\"playerRatings\",\"playerId\", 'weight', 'height', 'xStart', 'yStart', 'homeTeamId', 'awayTeamId', 'gameTime (min)' ], axis = 1, inplace = True)\n# pd.merge(team_perf, ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sns.boxplot(x=\"Result\", y=\"teamRatings\", data=team_perf);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(n=10,axis='columns',replace=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### WEAKNESSES (when they don't win)\nX_all = df[(df.teamId ==1612) &(df.result!=1) ]\ny_all = df[(df.teamId ==1612) &(df.result!=1)].iloc[:,-1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = X_all.iloc[:,2:-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 500, random_state=123)\nrf.fit(X_all, y_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_feature_importance = pd.DataFrame(rf.feature_importances_, index=df.iloc[:,2:-1].columns, columns=['feature importance']).sort_values('feature importance', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\ndf_feature_importance[0:10].plot(kind='bar');\n#fig.savefig('temp.png', transparent=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Player_Aggs3 = Player_Aggs_live50[Player_Aggs_live50.Position!=\"GKP\"]\n# Player_Aggs3 = Player_Aggs3.loc[:, ~Player_Aggs3.columns.isin([\"xStart\",\"height\",\"homeAway\",\"yStart\", \"weight\", \"name\",\"Result\", 'matchId', 'homeTeamId', 'awayTeamId'])]\n\n# Player_Aggs3 = Player_Aggs3.groupby(['playerId' ,'teamId',]).sum().reset_index()\n\n# PV = Player_Aggs3.playerId\n# TV = Player_Aggs3.teamId\n\n# Player_Aggs3 = Player_Aggs3.iloc[:,2:].div(Player_Aggs3[\"gameTime (min)\"], axis=0) *90\n# Player_Aggs3 = pd.concat([PV, TV, Player_Aggs3], axis =1)\n\n# # Player_Aggs3  = pd.merge(Player_Aggs2[[\"playerId\",\"teamId\"]], Player_Aggs3, how = 'left', on= 'playerId')\n# # Player_Aggs3 = Player_Aggs3.drop_duplicates()\n\n# Player_Aggs3.drop([\"gameTime (min)\"], inplace = True, axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering\nfrom scipy.cluster.hierarchy import dendrogram\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix diabates last name for visual\ntest[test.teamId==1610].iloc[-7:-6,0:1] = \"F.Diabate\"\n\n# test.iloc[3:4,0:1] =  \"M.Hamsik\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = test[(test.teamId==1639) & (test.Position!=\"GKP\")].iloc[:,:-2]\ndf3 = df3.fillna(0)\n# df = Player_Aggs3.loc[:, ~Player_Aggs3.columns.isin([\"homeAway\",\"shortName\", \"name\",\"Result\", 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\n# df = df[df.teamId==1609]\ndf3.drop(['teamId'], axis=1, inplace=True)\ndf3 = df3.replace([np.inf, -np.inf], np.nan).fillna(mean)\n\ndf_y  = pd.merge(df3['playerId'], Players[[\"shortName\", \"playerId\", \"teamId\"]], how = 'left', on='playerId')[[\"shortName\"]]\ndf_y = df_y.fillna(\"none\")\ny = df_y.values\nX  = df3.iloc[:,11:].values\n\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, stratify=y)\n# knn = KNeighborsClassifier(n_neighbors=5)\n# knn.fit(X_train, y_train)\n# print(knn.score(X_test, y_test)) # prints 0.87 - i.e. 87% accurate\n# walcott = df[df.playerId==7879].drop('playerId', axis=1).values\n# salah = df[df.playerId==120353].drop('playerId', axis=1).values\n# print(knn.predict(walcott)) # prints ['midfield']\n# print(knn.predict(salah))   # prints ['defence']\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Teams[Teams.name.str.contains(\"Wolves\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.cluster.hierarchy as shc\n\nax = plt.figure(figsize=(12, 5))  \nplt.title(\"Dendrograms\")  \ndend = shc.dendrogram(shc.linkage(X, method='ward'),labels=y, leaf_rotation=0, orientation=\"left\")\n\n\n#ax = df_feature_importance[0:10].plot(kind='bar', color=\"#F0BE33\")\n\n\n# ax.patch.set_facecolor('#241C24')\n# plt.y_ticks( color = \"white\")\n#ax.tick_params(axis='x', colors='white',size =14 )\n#.tick_params(axis='y', colors='white', size=14)\n#plt.ylabel(\"Feature Importance\", color = \"white\")\n\n#         fig, ax = plt.subplots(figsize=(15, 7))  # set size\n#         ax = dendrogram(linkage_matrix, **kwargs)\n#         plt.tick_params(axis='x', bottom='off', top='off', labelbottom='off')\n#         plt.tight_layout()\n#         plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n    os.chdir()\nexcept:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import AgglomerativeClustering","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_dendrogram(model, **kwargs):\n    # Create linkage matrix and then plot the dendrogram\n\n    # create the counts of samples under each node\n    counts = np.zeros(model.children_.shape[0])\n    n_samples = len(model.labels_)\n    for i, merge in enumerate(model.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1  # leaf node\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack([model.children_, model.distances_,\n                                    counts]).astype(float)\n    print(len(counts))\n    # Plot the corresponding dendrogram\n    shc.dendrogram(linkage_matrix, **kwargs)\n\n\n# setting distance_threshold=0 ensures we compute the full tree.\nmodel = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n\nmodel = model.fit(X)\nplt.title('Hierarchical Clustering Dendrogram')\n# plot the top three levels of the dendrogram\nplot_dendrogram(model, truncate_mode='level', p=8)\nplt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs3[Player_Aggs3.playerId==7879] # walcott\nPlayer_Aggs3[Player_Aggs3.playerId==120353] # salah","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Own Team"},{"metadata":{"trusted":true},"cell_type":"code","source":"teamTest.loc[:, ~teamTest.columns.isin([\"name\",\"Result\",'teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'gameTime (min)'])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Events_England.drop[(\"subEventId\",), ]\n\n\ntentacion","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import datetime\n# while datetime.datetime.now().hour < 13:\n#     x = 1+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig, ax = plt.subplots()\n# fig.set_size_inches(14,4)\n# plt.subplot(121)\n# sns.kdeplot(Events_England[\"xStart\"], Events_England['yStart'], shade = True)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Successful Vertical Yards Now Merge\n\n# df = Events_England.loc[Events_England.Result == \"Success\" ].groupby(['matchId','playerId'])['attackMetres'].sum().reset_index()\n# df2 = Events_England.loc[Events_England.Result == \"Failure\" ].groupby(['matchId','playerId'])['attackMetres'].sum().reset_index()\n\n# with names, positions and clubs for reference\n#df = pd.merge(Events_England.loc[Events_England.Result == \"Success\" ].groupby(['matchId','playerId'])['attackYards'].sum().reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on = 'playerId').sort_values(by ='attackYards', ascending = False)\n#df2 = pd.merge(Events_England.loc[Events_England.Result == \"Failure\" ].groupby(['matchId','playerId'])['attackYards'].sum().reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on = 'playerId').sort_values(by ='attackYards', ascending = False)\n\n# .sort_values(by ='attackYards', ascending = False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dataframes of brute sum of attacking yard attempts without success or failure measures\n\n#df  = pd.merge(Events_England.groupby(['matchId','playerId'])['attackYards'].agg(['sum']).reset_index(), Players[['playerId', 'shortName', \"Position\", 'clubName']], on ='playerId').sort_values(by ='sum', ascending = False).rename(columns={'sum':'attackYards'})\n# df = Events_England.groupby(['matchId','playerId'])['attackYards'].agg(['sum']).reset_index().sort_values(by ='sum', ascending = False).rename(columns={'sum':'attackYards'})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Player_Aggs = pd.merge(Player_Aggs, Matches[['matchId', \"Result\"]], how = 'left', on = 'matchId' )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Live match testing"},{"metadata":{},"cell_type":"markdown","source":"##### Team Aggregates and Clustering Tactics"},{"metadata":{"trusted":true},"cell_type":"code","source":"dropcols = ['playerId',\n'weight','height','xStart','yStart','homeTeamId','awayTeamId','gameTime (min)','FKCrossAccuracy','penaltiesConversion',\n'low_left_save_efficiency','mid_left_save_efficiency','high_left_save_efficiency','low_center_save_efficiency',\n'mid_center_save_efficiency','high_center_save_efficiency','low_right_save_efficiency','mid_right_save_efficiency',\n'high_right_save_efficiency','shotAccuracy','shortPassAccuracy','longPassAccuracy','shortLongPassRatio',\n'Result']\n\ndropcols_live = dropcols[0:9]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Team_Aggs_Matches = Player_Aggs.groupby(['matchId', 'teamId' ]).sum().reset_index()\nTeam_Aggs_Matches.drop(columns = dropcols, inplace=True, axis=1)\nTeam_Aggs_Matches = pd.merge(Team_Aggs_Matches, Matches[['matchId', \"Country\"]], on='matchId', how = 'left')\nTeams['Country'] = [row['name'] for row in Teams.area]\nTeam_Aggs = Team_Aggs_Matches.groupby(['teamId']).sum().reset_index()\nTeam_Aggs.drop(columns = 'matchId', inplace=True, axis=1)\nTeam_Aggs = pd.merge(Team_Aggs, Teams[['teamId', 'Country']], how = 'left', on = 'teamId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Team_Aggs_Matches_live = Player_Aggs_live.groupby(['matchId', 'teamId' ]).sum().reset_index()\nTeam_Aggs_Matches_live.drop(columns = dropcols_live, inplace=True, axis=1)\nTeam_Aggs_Matches_live = pd.merge(Team_Aggs_Matches_live, Matches[['matchId', \"Country\"]], on='matchId', how = 'left')\nTeams['Country'] = [row['name'] for row in Teams.area]\nTeam_Aggs_live = Team_Aggs_Matches_live.groupby(['teamId']).sum().reset_index()\nTeam_Aggs_live.drop(columns = 'matchId', inplace=True, axis=1)\nTeam_Aggs_live = pd.merge(Team_Aggs_live, Teams[['teamId', 'Country']], how = 'left', on = 'teamId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = Matches_df(Team_Aggs_Matches, Team_Aggs)\nresult_live = Matches_df(Team_Aggs_Matches_live, Team_Aggs_live)\ny_all = result[\"Result\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all_live = result_live.loc[:, ~result_live.columns.isin([\"awayCounterAttackGoal\", \n                                                           \"Result\",'teamId', 'matchId', 'homeTeamId', \n                                                           'awayTeamId', 'homeGoal_Value','awayGoal_Value', \n                                                           'awayCornerAssists', 'awayPenaltyNotScored', 'homeCornerAssists'])]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = result.loc[:, ~result.columns.isin(['teamId', 'matchId', 'homeTeamId', 'awayTeamId', 'awayGoal_Value','homegoalsAllowed', 'awaygoalsAllowed'\n                                           ,'homeGoal_low_left', 'homeGoal_mid_left', 'awayGoal_mid_right',\n                                           'homeGoal_Value', 'homeCrossAssists', 'homeCornerAssists',\n                                           'homeGoal_low_center', 'homeTotalAssists','homeRightFootGoal', 'awayRightFootGoal'\n                                           ,'homeRightFootGoal', 'awayRightFootGoal',\n       'homeLeftFootGoal', 'awayLeftFootGoal', 'homeTotalAssists',\n       'awayTotalAssists',\"Result\", 'awayGoal_low_left', 'awayGoal_low_center',\n       'homeGoal_low_right', 'awayGoal_low_right','homeHeader/Body_Goal', 'awayHeader/Body_Goal','awayCrossAssists',\n                                           'awayCrossAssists','awayInterceptionGoal',\n 'homeInterceptionGoal','awayOwnGoals','homeFKCrossAssists', 'homeGoal_high_left','awayFKCrossAssists',\n 'homeOwnGoals','homeGoal_high_right','awayGoal_high_center',\n 'awayGoal_high_left','awayInterceptionGoal','homeInterceptionGoal','awayOwnGoals','awayPenaltyNotScored',\n 'homeFKCrossAssists','homeGoal_high_left','awayFKCrossAssists',\n'awayGoal_mid_left', 'homeGoal_mid_right','homeGoal_mid_center','awayGoal_high_right','awayGoal_mid_center',\n 'homeGoal_high_center','awayCornerAssists','homeOwnGoals', 'homeGoal_high_right','awayGoal_high_center'                                      \n 'awayGoal_high_left', 'homeCounterAttackGoal', 'awayCounterAttackGoal'])]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all_live = X_all_live.replace([np.inf, -np.inf], np.nan)\nX_all_live = X_all_live.fillna(X_all_live.mean())\nX_train_live, X_test_live, y_train_live, y_test_live = train_test_split(X_all_live, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Experiment: Extracting features of team playing style using Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"# param_grid = {\n#     'n_estimators': [200,400,500, 700,1000,2000]\n# }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Subset AKA live match trials"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_all = X_all.replace([np.inf, -np.inf], np.nan)\nX_all = X_all.fillna(X_all.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, shuffle=True, test_size= 0.2, train_size=0.8, random_state=3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators = 1000, random_state=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV_rfc = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV_rfc.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV_rfc.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [-1,0,1]\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred, labels = labels))\nprint('accuracy score: {0:.4f}'.format(accuracy_score(y_test,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = list(clf.feature_importances_.argsort()[0:25])\ncol = list(X_train.columns[idx])\n# modelname.feature_importance_\ny = clf.feature_importances_[0:25]\n#plot\nfig, ax = plt.subplots() \nwidth = 0.4 # the width of the bars \nind = np.arange(len(y)) # the x locations for the groups\nax.barh(ind, y, width, color='green')\nax.set_yticks(ind+width/10)\nax.set_yticklabels(col, minor=False)\nplt.title('Feature importance in RandomForest Classifier')\nplt.xlabel('Relative importance')\nplt.ylabel('feature') \nplt.figure(figsize=(5,5))\nfig.set_size_inches(6.5, 4.5, forward=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(pd.crosstab(y_test, y_pred, rownames=['Actual Result'], colnames=['Predicted Result']))\nclass_name = list(set(y_test))\nprint(class_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# estimator_nonlimited = clf.estimators_[5]\n# fn = list(X_train.columns)\n# # from sklearn.tree import export_graphviz\n# # export_graphviz(estimator_limited, out_file='tree_limited.dot', feature_names = iris.feature_names,\n# #                 class_names = iris.target_names,\n# #                 rounded = True, proportion = False, precision = 2, filled = True)\n\n# export_graphviz(estimator_nonlimited, out_file='tree_nonlimited.dot', feature_names = fn,\n#                 class_names = [\"W\", \"L\", 'D'],\n#                 rounded = True, proportion = False, precision = 2, filled = True)\n\n\n# import pydot\n\n# (graph,) = pydot.graph_from_dot_file('tree_nonlimited.dot')\n# graph.write_png('tree_nonlimited.png')\n# graph.draw('tree_nonlimited.png')\n\n\n# # !dot -Tpng tree_limited.dot -o tree_nonlimited.png -Gdpi=600\n# # from IPython.display import Image\n# # Image(filename = 'tree_nonlimited.png')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dtreeviz.trees import *\nimport dtreeviz\nfrom IPython.core.display import display, HTML\nfrom dtreeviz.trees import dtreeviz\n\nfn = list(X_train.columns)\ncn = [-1,0,1]\n\ndtree = tree.DecisionTreeClassifier(random_state=0)\ndtree = dtree.fit(X_train, y_train)\nviz = dtreeviz(dtree,\n               X_train,\n               y_train,\n               feature_names=fn, \n               class_names=cn,\n               fancy=False)\n\nviz.view()\n\n# display(HTML(viz.svg()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predict_proba = clf.predict_proba(X_test)\n\n# Compute ROC curve and ROC AUC for each class\nn_classes = 3\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nall_y_test_i = np.array([])\nall_y_predict_proba = np.array([])\nfor i in [-1,0,1]:\n    y_test_i = list(map(lambda x: 1 if x == i else 0, list(y_test)))\n    if len(all_y_test_i) >0:\n        all_y_test_i = np.concatenate([all_y_test_i, y_test_i])\n    else:\n        all_y_test_i = y_test_i\n    all_y_predict_proba = np.concatenate([all_y_predict_proba, y_predict_proba[:, i]])\n    fpr[i], tpr[i], _ = roc_curve(y_test_i, y_predict_proba[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"average\"], tpr[\"average\"], _ = roc_curve(all_y_test_i, all_y_predict_proba)\nroc_auc[\"average\"] = auc(fpr[\"average\"], tpr[\"average\"])\n\n\n# Plot average ROC Curve\nplt.figure()\nplt.plot(fpr[\"average\"], tpr[\"average\"],\n         label='Average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"average\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\n# Plot each individual ROC curve\nfor i in [-1,0,1]:\n    plt.plot(fpr[i], tpr[i], lw=2,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generate a no skill prediction (majority class)\n# ns_probs = [0 for _ in range(len(y_test))]\n# ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n# plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n\n# #Now calculate the AUC for each class separately\n\ny_predict_proba = clf.predict_proba(X_test)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nall_y_test_i = np.array([])\nall_y_predict_proba = np.array([])\n\nWDL = [\"Draw\",\"Home Win\", \"Home Loss\"]\n\nfor pp in [-1,0,1]:\n    fpr, tpr, thresholds = metrics.roc_curve(y_test,  \n                     clf.predict_proba(X_test)[:,pp], pos_label = pp)\n    plt.plot(fpr, tpr,  marker='.', label= WDL[pp])\n    auroc = round(metrics.auc(fpr, tpr),2)\n    print('RF',WDL[pp],'--AUC--->',auroc)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# show the legend\nplt.legend()\n# show the plot\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_matches = Matches.shape[0]\nn_features = Matches.shape[1] -1\nn_homewins =  len(Matches[Matches.Result==1])\nwin_rate = (float(n_homewins) / (n_matches)) * 100\nn_homeloss =  len(Matches[Matches.Result==-1])\nloss_rate = (float(n_homeloss) / (n_matches)) * 100\nprint(\"Total number of matches: {}\".format(n_matches))\nprint(\"Number of features: {}\".format(n_features))\nprint('Number of matches won by home side: {}'.format(n_homewins))\nprint('Win rate of home team {:2f}%'.format(win_rate))\nprint('Loss rate of home team {:2f}%'.format(loss_rate))\nprint(collections.Counter(Matches.Result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropcols = [\n 'playerId',\n 'weight',\n 'height',\n 'xStart',\n 'yStart',\n 'homeTeamId',\n 'awayTeamId',\n 'gameTime (min)',\n#  'AccurateAttackMetres',\n#  'InaccurateAttackMetres',\n#  'Goal_Value',\n#  'SimulationFouls',\n#  'FoulsCommited',\n#  'Clearances',\n#  'AccLaunchMetres',\n#  'InaccLaunchMetres',\n#  'FKKeyCross',\n#  'FKCrossAssists',\n 'FKCrossAccuracy',\n 'penaltiesConversion',\n#  'dangerousOpponentHalfRecoveries',\n#  'dangerousOwnHalfBallLost',\n#  'dangerousDefDuelsLost',\n 'low_left_save_efficiency',\n 'mid_left_save_efficiency',\n 'high_left_save_efficiency',\n 'low_center_save_efficiency',\n 'mid_center_save_efficiency',\n 'high_center_save_efficiency',\n 'low_right_save_efficiency',\n 'mid_right_save_efficiency',\n 'high_right_save_efficiency',\n#  'goalsAllowed',\n#  'GkSaves',\n#  'AccurateHandPass',\n#  'InaccurateHandPass',\n#  'GKLeavingLineInstance',\n#  'SuccessfulAccels',\n#  'FailedAccels',\n#  'CumAccelerationDist',\n#  'AccelsDistIntoFinal3rd',\n#  'AccelsDistWithinFinal3rd',\n#  'CrossAssists',\n#  'RightFootCross',\n#  'LeftFootCross',\n#  'CrossKeyPass',\n#  'AccCrosses',\n#  'InaccCrosses',\n#  'AccCrossesIntoBox',\n#  'InaccCrossesIntoBox',\n#  'SlidingTacklesWon',\n#  'SlidingTacklesLost',\n#  'GroundDefDuelsWon',\n#  'GroundDefDuelsLost',\n#  'DefensiveAnticipations',\n#  'GroundLooseBallsWon',\n#  'GroundLooseBallsLost',\n#  'GroundAttackDuelsWon',\n#  'GroundAttackDuelsLost',\n#  'OffensiveTouchesBox',\n#  'Goal_low_left',\n#  'Goal_mid_left',\n#  'Goal_high_left',\n#  'Goal_low_center',\n#  'Goal_mid_center',\n#  'Goal_high_center',\n#  'Goal_low_right',\n#  'Goal_mid_right',\n#  'Goal_high_right',\n 'shotAccuracy',\n#  'ShotsOnTarget',\n#  'ShotsOffTarget',\n#  'ShotOpportunities',\n#  'FreeKickShotAcc',\n#  'FreeKickShotInacc',\n#  'PenaltyNotScored',\n#  'Header/Body_Goal',\n#  'RightFootGoal',\n#  'LeftFootGoal',\n#  'CounterAttackGoal',\n#  'InterceptionGoal',\n#  'OwnGoals',\n#  'AerialDuelsWon',\n#  'AerialDuelsLost',\n 'shortPassAccuracy',\n 'longPassAccuracy',\n 'shortLongPassRatio',\n#  'InaccPassesWithinFinalThird',\n#  'AccPassesWithinFinalThird',\n#  'AccPassesIntoFinalThird',\n#  'InaccPassesIntoFinalThird',\n#  'AccThroughsIntoFinalThird',\n#  'InaccurateSmartPasses',\n#  'AccurateSmartPasses',\n#  'InaccurateThroughPasses',\n#  'AccurateThroughPasses',\n#  'AccurateKeyPasses',\n#  'InaccurateKeyPasses',\n#  'TotalAssists',\n#  'CounterAttackInvolvements',\n#  'PassLostDangerous',\n#  'CounterAttackIntercept',\n#  'SuccessfulInterceptions',\n#  'InaccurateForwardPasses',\n#  'AccurateForwardPasses',\n#  'CornerAssists',\n#  'CornerOpportunitiesCreated',\n#  'SuccessfulCorners',\n#  'FailedCorners',\n 'Result']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### KMeans for detecting and visualizing team formations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# live adaptable formation\ndef team_formation(event_df, teamId, matchId):\n    event_df = event_df[(event_df.teamId==teamId)&(event_df.matchId==matchId)]\n    maxtime = event_df.eventSec.max()\n    if maxtime > 1200:\n        mintime = maxtime - 1200 # last 20mins of match data for formation revelation\n    else:\n        mintime = 0\n    x1 = np.array(event_df[(event_df.eventSec > mintime)].xStart) \n    x2 = np.array(event_df[(event_df.eventSec > mintime)].yStart)\n    X = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n    return x1, x2, X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the data \nx1, x2, X = team_formation(Events_England, 1609, 2499719)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=11, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfig.set_size_inches(10, 7)\nax=fig.add_subplot(1,1,1)\n\n# pitch borderline and centrer line\nplt.plot([0,0],[0,100], color=\"white\")\nplt.plot([0,100],[100,100], color=\"white\")\nplt.plot([100,100],[100,0], color=\"white\")\nplt.plot([100,0],[0,0], color=\"white\")\nplt.plot([50,50],[0,100], color=\"white\") # center line\n\n# left penalty area\nplt.plot([16.5,16.5],[75,25],color=\"white\")\nplt.plot([0,16.5],[75,75],color=\"white\")\nplt.plot([16.5,0],[25,25],color=\"white\")\n\n#Right Penalty Area\nplt.plot([83.5,100],[75,75],color=\"white\")\nplt.plot([83.5,83.5],[75,25],color=\"white\")\nplt.plot([83.5,100],[25,25],color=\"white\")\n\n#Left 6-yard Box\nplt.plot([0,5.5],[64,64],color=\"white\")\nplt.plot([5.5,5.5],[64,36],color=\"white\")\nplt.plot([5.5,0.5],[36,36],color=\"white\")\n\n#Right 6-yard Box\nplt.plot([100,94.5],[64,64],color=\"white\")\nplt.plot([94.5,94.5],[64,36],color=\"white\")\nplt.plot([94.5,100],[36,36],color=\"white\")\n\n#Prepare Circles\ncentreCircle = plt.Circle((50,50),9.15,color=\"white\",fill=False)\ncentreSpot = plt.Circle((50,50),0.6,color=\"white\")\nleftPenSpot = plt.Circle((11,50),0.6,color=\"white\")\nrightPenSpot = plt.Circle((89,50),0.6,color=\"white\")\n\n# zones\nplt.plot([100,0],[25,25],color=\"white\", linestyle='--') \nplt.plot([100,0],[75,75],color=\"white\", linestyle='--') \nplt.plot([100,0],[25,25],color=\"white\", linestyle='--') \nplt.plot([33,33],[75,25],color=\"white\", linestyle='--')\nplt.plot([67,67],[75,25],color=\"white\", linestyle='--')\nplt.plot([33,33],[100,75],color=\"white\", linestyle='--')\nplt.plot([16.5,16.5],[100,75],color=\"white\", linestyle='--')\nplt.plot([67,67],[100,75],color=\"white\", linestyle='--')\nplt.plot([83.5,83.5],[100,75],color=\"white\", linestyle='--')\nplt.plot([33,33],[0,25],color=\"white\", linestyle='--')\nplt.plot([16.5,16.5],[0,25],color=\"white\", linestyle='--')\nplt.plot([67,67],[0,25],color=\"white\", linestyle='--')\nplt.plot([83.5,83.5],[0,25],color=\"white\", linestyle='--')\nplt.plot([16.5,83.5],[50,50],color=\"white\", linestyle='--')\nplt.plot([33,33],[0,25],color=\"white\", linestyle='--')\nplt.plot([0,16.5],[64,64],color=\"white\", linestyle='--')\nplt.plot([0,16.5],[36,36],color=\"white\", linestyle='--')\nplt.plot([83.5,100],[64,64],color=\"white\", linestyle='--')\nplt.plot([83.5,100],[36,36],color=\"white\", linestyle='--')\n\n# Fill with green\ngreen = patches.Rectangle((0, 0), 100, 100, linewidth=0.1,\n                             edgecolor='r', facecolor='darkgreen', zorder=0, alpha = 0.8)\nax.add_patch(green)\n\n#Draw Circles\nax.add_patch(centreCircle)\nax.add_patch(centreSpot)\nax.add_patch(leftPenSpot)\nax.add_patch(rightPenSpot)\n\n#Prepare Arcs\nleftArc = Arc((11,50),height=18.3,width=18.3,angle=0,theta1=310,theta2=50,color=\"white\")\nrightArc = Arc((89,50),height=18.3,width=18.3,angle=0,theta1=130,theta2=230,color=\"white\")\n\n#Draw Arcs\nax.add_patch(leftArc)\nax.add_patch(rightArc)\n\n# #Tidy Axes\n# plt.axis('off')\n\n# #K-Means Live formation\n# plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=30, cmap='viridis')\n# plt.scatter(centers[:, 0], centers[:, 1], c='red', s=600, alpha=0.5)\n\n#Heat Map of Player and Action Type\nteam = Events_Spain[(Events_Spain.playerId == 3359) & (Events_Spain.matchId == 2565907)  & (Events_Spain.subEventName==\"Shot\") ]\nsns.kdeplot(team[\"xStart\"],team[\"yStart\"], shade=True)\n# team2 = Events_Spain[(Events_Spain.playerId == 3322) & (Events_Spain.matchId == 2565907)  & (Events_Spain.subEventName==\"Shot\") ]\n# sns.kdeplot(team2[\"xStart\"],team2[\"yStart\"], shade=True, color=\"Red\")\n\n# plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=11, cmap='viridis')\n# centers = kmeans.cluster_centers_\n# plt.scatter(centers[:, 0], centers[:, 1], c='red', s=400, alpha=0.5)\n\nplt.ylim(100, 0)\nplt.xlim(0, 100)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the data \nx1 = np.array(Player_Aggs[Player_Aggs['gameTime (min)']>45].xStart) \nx2 = np.array(Player_Aggs[Player_Aggs['gameTime (min)']>45].yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distortions = [] \ninertias = [] \nmapping1 = {} \nmapping2 = {} \nK = range(1,15) \n  \nfor k in K: \n    #Building and fitting the model \n    kmeanModel = KMeans(n_clusters=k).fit(X) \n    kmeanModel.fit(X)     \n      \n    distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n                      'euclidean'),axis=1)) / X.shape[0]) \n    inertias.append(kmeanModel.inertia_) \n  \n    mapping1[k] = sum(np.min(cdist(X, kmeanModel.cluster_centers_, \n                 'euclidean'),axis=1)) / X.shape[0] \n    mapping2[k] = kmeanModel.inertia_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(K, inertias, 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Inertia') \nplt.title('The Elbow Method using Inertia') \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(K, distortions, 'bx-') \nplt.xlabel('Values of K') \nplt.ylabel('Distortion') \nplt.title('The Elbow Method using Distortion') \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=4)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is what four pitch area location clusters look like","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### Traditional 11 pitch positions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Liverpool formation last twenty minutes versus Man Utd at Anfield\nnp.array(Events_England[(Events_England.teamId == 1612) (Events_England.matchId==2499793) & (Events_England.eventSec <3700) * (Events_England.eventSec > 2400)].xStart)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the data for Liverpool live formation at 60mins\n\nx1 = np.array(Events_England[(Events_England.teamId == 1612) &(Events_England.matchId==2499793) & (Events_England.eventSec <3700) & (Events_England.eventSec > 1900)].xStart)\nx2 = np.array(Events_England[(Events_England.teamId == 1612) &(Events_England.matchId==2499793) & (Events_England.eventSec <3700) & (Events_England.eventSec > 1900)].yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=800, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=22)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparing Two Teams in a head to head"},{"metadata":{"trusted":true},"cell_type":"code","source":"Teams[Teams[\"name\"].str.contains('Barcelona')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating the data\nmanUtdBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\nmanUtdGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\nliverpoolGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1612) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\nliverpoolBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1612) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\nbarcelonaBad = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==-1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==1)))]\nbarcelonaGood = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676) &(((Player_Aggs.homeAway==\"home\") & (Player_Aggs.Result==1)) | ((Player_Aggs.homeAway==\"away\") & (Player_Aggs.Result==-1)))]\n\n\nx1 = np.array(manUtdBad.xStart) \nx2 = np.array(manUtdBad.yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters2 = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = np.array(manUtdGood.xStart) \nx2 = np.array(manUtdGood.yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n# plt.scatter(centers2[:, 0], centers2[:, 1], c='red', s=200, alpha=0.5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"manUtd = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==1611)]\nbarca = Player_Aggs[(Player_Aggs['gameTime (min)']>45) & (Player_Aggs.teamId ==676)]       ","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"## Man Utd\nx1 = np.array(manUtd.xStart) \nx2 = np.array(manUtd.yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n\nkmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"## Barcelona\nx1 = np.array(barca.xStart) \nx2 = np.array(barca.yStart)\nX = np.array(list(zip(x1, x2))).reshape(len(x1), 2) \n\nkmeans = KMeans(n_clusters=11)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\nplt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Events_England = pd.read_csv('eventsEvents_England_processed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Player_Aggs_live = pd.read_csv('eventsPlayer_Aggs_live.csv')\n# Player_Aggs = pd.read_csv('eventsPlayer_Aggs.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Player_Aggs_live.drop(['Unnamed: 0'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def Matches_df_fDNN(TAM, TA):\n    \n#     df2 = TAM.groupby('matchId').agg(list).reset_index()\n#     df2.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)\n#     df3 = pd.DataFrame(None, columns = list(TA.columns))\n\n#     for index, col in enumerate(list(TAM.columns)):\n#         df3[col] = df2.iloc[:,index]\n\n#     df4 = pd.concat([df3, pd.DataFrame(df3['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n#     result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n#     #df4.drop([\"Country\"], axis=1, inplace=True)\n\n#     for var in list(result.columns)[2:-5]:\n#         result = pd.concat([result, pd.DataFrame(df3[var].to_list(), columns=[\"1_\" + var, \"2_\" + var])], axis=1, sort = False)\n\n#         # Correctly apply allocate home and away aggregate statistics to correct teams\n#         result['home'+var] = (\n#             np.select(\n#                 condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n#                 choicelist=[result[\"1_\" + var], result[\"2_\" + var]]))\n\n#         result['away'+var] = (\n#             np.select(\n#                 condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n#                 choicelist=[result[\"1_\" + var], result[\"2_\" + var]]))\n\n#         # # drop useless columns that have been replaced\n#         result.drop([ var, \"1_\" + var, \"2_\" + var], inplace = True, axis = 1 )\n\n#     # # drop useless columns that have been replaced\n#     result.drop(['teamId',\"team1\", \"team2\"], inplace = True, axis = 1 )\n#     result = pd.merge(result, Matches[['matchId', \"Result\"]], on='matchId', how = 'left')\n#     return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def Matches_df(TAM, TA):\n    \n#     df2 = TAM.groupby('matchId').agg(list).reset_index()\n#     df2.drop([\"homeTeamId\", \"awayTeamId\"], inplace=True, axis=1)\n#     df3 = pd.DataFrame(None, columns = list(TA.columns))\n\n#     for index, col in enumerate(list(TAM.columns)):\n#         df3[col] = df2.iloc[:,index]\n\n#     df4 = pd.concat([df3, pd.DataFrame(df3['teamId'].to_list(), columns=['team1','team2'])], axis=1, sort = False)\n#     result = pd.merge(df4, Matches[['matchId', \"homeTeamId\", \"awayTeamId\"]], on='matchId', how='inner')\n#     #df4.drop([\"Country\"], axis=1, inplace=True)\n\n#     for var in list(result.columns)[1:-6]:\n#         result = pd.concat([result, pd.DataFrame(df3[var].to_list(), columns=[var+\"1\",var+\"2\"])], axis=1, sort = False)\n\n#         # Correctly apply allocate home and away aggregate statistics to correct teams\n#         result['home'+var] = (\n#             np.select(\n#                 condlist=[result['team1'] == result['homeTeamId'], result['team2'] == result['homeTeamId']], \n#                 choicelist=[result[var+\"1\"], result[var+\"2\"]]))\n\n#         result['away'+var] = (\n#             np.select(\n#                 condlist=[result['team1'] == result['awayTeamId'], result['team2'] == result['awayTeamId']], \n#                 choicelist=[result[var+\"1\"], result[var+\"2\"]]))\n\n#         # # drop useless columns that have been replaced\n#         result.drop([ var, var+\"1\", var+\"2\"], inplace = True, axis = 1 )\n\n#     # # drop useless columns that have been replaced\n#     result.drop(['teamId',\"team1\", \"team2\"], inplace = True, axis = 1 )\n#     result = pd.merge(result, Matches[['matchId', \"Result\"]], on='matchId', how = 'left')\n#     return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #### ORIGINAL\n\n# dropcols = ['playerId',\n# 'weight','height','xStart','yStart','homeTeamId','awayTeamId','gameTime (min)','penaltiesConversion',\n# 'low_left_save_efficiency','mid_left_save_efficiency','high_left_save_efficiency','low_center_save_efficiency',\n# 'mid_center_save_efficiency','high_center_save_efficiency','low_right_save_efficiency','mid_right_save_efficiency',\n# 'high_right_save_efficiency','shotAccuracy','shortPassAccuracy','longPassAccuracy','shortLongPassRatio',\n# 'Result'][0:7]\n\n# dropcols_live =  dropcols[0:7]\n\n# Team_Aggs_Matches = Player_Aggs2.groupby(['matchId', 'teamId' ]).sum().reset_index()\n# Team_Aggs_Matches.drop(columns = dropcols, inplace=True, axis=1)\n\n# Team_Aggs = Team_Aggs_Matches.groupby(['teamId']).sum().reset_index()\n# Team_Aggs.drop(columns = ['matchId'], inplace=True, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We performed this and found our best params which are used in the model above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### RANDOM FORESTS WITh GRIDSEARCH\n\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # summarize results\n\n# print(\"best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n# means = grid_result.cv_results_['mean_test_score']\n# stds = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n# for mean, stdev, param in zip(means, stds, params):\n#     print(\"%f (%f) with: %r\" % (mean, stdev, param))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = list(clf.feature_importances_.argsort()[0:25])\ncol = list(X_train.columns[idx])\n\n# modelname.feature_importance_\n\ny = clf.feature_importances_[0:25]\n\n# plot\nfig, ax = plt.subplots() \nwidth = 0.4 # the width of the bars \nind = np.arange(len(y)) # the x locations for the groups\nax.barh(ind, y, width, color='green')\nax.set_yticks(ind+width/10)\nax.set_yticklabels(col, minor=False)\nplt.title('Feature importance in RandomForest Classifier')\nplt.xlabel('Relative importance')\nplt.ylabel('feature') \nplt.figure(figsize=(5,5))\nfig.set_size_inches(6.5, 4.5, forward=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = Player_Aggs_live30.iloc[:,:15]\ndf2 = Player_Aggs_live30.iloc[:,15:]\ndf2 = df2.replace([np.inf, -np.inf], np.nan)\ndf2 = df2.fillna(0)\n\nmin_max_scaler = preprocessing.MinMaxScaler()\nx_scaled = min_max_scaler.fit_transform(df2.values)\ndf2 = pd.DataFrame(x_scaled, columns = df2.columns)\n\nbase_imp = imp_df(df2.columns, rf.feature_importances_)\nxxx = base_imp.transpose()\nxxx.columns = xxx.iloc[0]\nxxx = xxx.drop(xxx.index[[0]])\nxxx = xxx.reindex(sorted(xxx.columns), axis=1)\ndf2 = df2.reindex(sorted(df2.columns), axis=1)\ndf2 = df2.multiply(xxx.values)\ndf2[negatives] = df2[negatives].multiply(-1)\ndf2[\"sum\"] = df2.sum(axis=1)\ndf2 = pd.concat([df1, df2], axis=1)\ndf2 = pd.merge(df2, df[[\"matchId\", 'teamId', \"Result\"]], on =['matchId', \"teamId\"], how = 'left' )\n#df2 = df2.loc[:, (df2 != 0).any(axis=0)]\ndf2['playerRatings']=  np.where(df2['gameTime (min)'] ==0, 0, df2['sum'])\ndf2['playerRatings'] = df2['playerRatings'].multiply(94 / df2.playerRatings.max())\ndf2.drop([\"sum\"], axis=1, inplace=True)\ncollections.Counter(df2.sort_values(\"playerRatings\", ascending=False).iloc[0:100,:].Position)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from dtreeviz.trees import *\nimport dtreeviz\nfrom IPython.core.display import display, HTML\nfrom dtreeviz.trees import dtreeviz\n\nfn = list(X_all.columns)\ncn = [-1,0,1]\n\n_ = tree.plot_tree(clf.estimators_[0], feature_names=X_all.columns, filled=True, max_depth=10)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}